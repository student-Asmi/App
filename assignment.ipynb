{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "14r5usUfOKiijqueBgOFszglIq-LDOjbt",
      "authorship_tag": "ABX9TyNJAcRbPbye7n7tNcY0D/zU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/student-Asmi/App/blob/main/assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZyofb2hUJ58",
        "outputId": "87959a12-31d5-4981-ab32-90a9d8c1b2bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lark in /usr/local/lib/python3.12/dist-packages (1.3.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install lark pandas numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import re\n",
        "\n",
        "def normalize_text(text):\n",
        "    return re.sub(r\"\\s+\", \" \", text.lower()).strip()\n",
        "\n",
        "def extract_numbers(text):\n",
        "    text = text.lower()\n",
        "    match = re.findall(r\"\\d+\", text)\n",
        "    nums = [int(n) for n in match] if match else []\n",
        "\n",
        "    if \"million\" in text:\n",
        "        nums = [nums[0] * 1_000_000]\n",
        "    if \"thousand\" in text:\n",
        "        nums = [nums[0] * 1000]\n",
        "\n",
        "    return nums\n",
        "\n",
        "def convert_indicator(text):\n",
        "    if \"moving average\" in text or \"ma\" in text:\n",
        "        nums = extract_numbers(text)\n",
        "        if nums:\n",
        "            return f\"SMA(close,{nums[0]})\"\n",
        "\n",
        "    if \"rsi\" in text:\n",
        "        nums = extract_numbers(text)\n",
        "        period = nums[0] if nums else 14\n",
        "        return f\"RSI(close,{period})\"\n",
        "\n",
        "    return None\n",
        "\n",
        "def parse_condition(sentence):\n",
        "    sentence = normalize_text(sentence)\n",
        "\n",
        "    left = None\n",
        "    op = None\n",
        "    right = None\n",
        "\n",
        "    if \"close\" in sentence or \"price\" in sentence:\n",
        "        left = \"close\"\n",
        "    elif \"volume\" in sentence:\n",
        "        left = \"volume\"\n",
        "\n",
        "    if \"above\" in sentence:\n",
        "        op = \">\"\n",
        "    elif \"below\" in sentence:\n",
        "        op = \"<\"\n",
        "\n",
        "    right_indicator = convert_indicator(sentence)\n",
        "    if right_indicator:\n",
        "        right = right_indicator\n",
        "\n",
        "    nums = extract_numbers(sentence)\n",
        "    if nums and not right:\n",
        "        right = nums[0]\n",
        "\n",
        "    if left and op and right:\n",
        "        return f\"{left} {op} {right}\"\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def nl_to_dsl(nl_text):\n",
        "    text = normalize_text(nl_text)\n",
        "    parts = re.split(r\" and | , \", text)\n",
        "\n",
        "    rules = []\n",
        "    for p in parts:\n",
        "        cond = parse_condition(p)\n",
        "        if cond:\n",
        "            rules.append(cond)\n",
        "\n",
        "    mode = \"ENTRY\"\n",
        "    if \"exit\" in text or \"sell\" in text:\n",
        "        mode = \"EXIT\"\n",
        "    elif \"buy\" in text or \"enter\" in text:\n",
        "        mode = \"ENTRY\"\n",
        "\n",
        "    rule_text = \" AND \".join(rules)\n",
        "    return f\"{mode}: {rule_text}\"\n"
      ],
      "metadata": {
        "id": "9_JQODlmYdUh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def normalize_text(text):\n",
        "    return re.sub(r\"\\s+\", \" \", text.lower()).strip()\n",
        "\n",
        "def extract_numbers(text):\n",
        "    text = text.lower()\n",
        "    match = re.findall(r\"\\d+\", text)\n",
        "    nums = [int(n) for n in match] if match else []\n",
        "    if \"million\" in text and nums:\n",
        "        nums = [nums[0] * 1_000_000]\n",
        "    if \"thousand\" in text and nums:\n",
        "        nums = [nums[0] * 1000]\n",
        "    return nums\n",
        "\n",
        "\n",
        "def parse_one_condition(sentence):\n",
        "    \"\"\"\n",
        "    Ek condition ko JSON me convert karo.\n",
        "    - \"close price is above the 20-day moving average\"\n",
        "    - \"volume is above 1 million\"\n",
        "    - \"rsi(14) is below 30\"\n",
        "    \"\"\"\n",
        "    rule = parse_cross_condition(sentence)\n",
        "    if rule:\n",
        "     return rule\n",
        "\n",
        "    s = normalize_text(sentence)\n",
        "\n",
        "    left = None\n",
        "    op = None\n",
        "    right = None\n",
        "\n",
        "    # 1) OPERATOR detect karo\n",
        "    if \"above\" in s or \"greater than\" in s:\n",
        "        op = \">\"\n",
        "    elif \"below\" in s or \"less than\" in s:\n",
        "        op = \"<\"\n",
        "    elif \"equal\" in s:\n",
        "        op = \"==\"\n",
        "\n",
        "    # 2) Special case: RSI\n",
        "    if \"rsi\" in s:\n",
        "        # numbers: e.g. \"rsi(14) is below 30\" -> [14, 30]\n",
        "        nums = re.findall(r\"\\d+\", s)\n",
        "        period = int(nums[0]) if len(nums) >= 1 else 14\n",
        "        # threshold last number hoga (e.g. 30)\n",
        "        threshold = int(nums[-1]) if len(nums) >= 2 else 30\n",
        "\n",
        "        left = f\"rsi(close,{period})\"\n",
        "        right = threshold\n",
        "\n",
        "        return {\n",
        "            \"left\": left,\n",
        "            \"operator\": op,\n",
        "            \"right\": right\n",
        "        }\n",
        "\n",
        "    # 3) LEFT side: close / volume (non-RSI case)\n",
        "    if \"close\" in s or \"price\" in s:\n",
        "        left = \"close\"\n",
        "    elif \"volume\" in s:\n",
        "        left = \"volume\"\n",
        "\n",
        "    # 4) RIGHT side KE LIYE:\n",
        "    #    (a) moving average\n",
        "    if \"moving average\" in s or \"ma\" in s:\n",
        "        nums = extract_numbers(s)\n",
        "        period = nums[0] if nums else 20\n",
        "        right = f\"sma({left},{period})\"\n",
        "\n",
        "    #    (b) plain number (e.g. \"1 million\")\n",
        "    if right is None:\n",
        "        nums = extract_numbers(s)\n",
        "        if nums:\n",
        "            right = nums[0]\n",
        "\n",
        "    if left and op and right is not None:\n",
        "        return {\"left\": left, \"operator\": op, \"right\": right}\n",
        "    else:\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "ItISZY7FtfH5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nl_to_json_rules(text):\n",
        "    t = normalize_text(text)\n",
        "\n",
        "    is_entry = any(word in t for word in [\"buy\", \"enter\", \"trigger entry\"])\n",
        "    is_exit = any(word in t for word in [\"exit\", \"sell\"])\n",
        "\n",
        "    entry_rules = []\n",
        "    exit_rules = []\n",
        "\n",
        "    parts = re.split(r\"\\band\\b\", t)\n",
        "\n",
        "    for part in parts:\n",
        "        rule = parse_one_condition(part)\n",
        "        if rule:\n",
        "            if is_exit:\n",
        "                exit_rules.append(rule)\n",
        "            else:\n",
        "                entry_rules.append(rule)\n",
        "\n",
        "    return {\n",
        "        \"entry\": entry_rules,\n",
        "        \"exit\": exit_rules\n",
        "    }\n"
      ],
      "metadata": {
        "id": "UxPxRdSMvIXQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def normalize_text(text):\n",
        "    return re.sub(r\"\\s+\", \" \", text.lower()).strip()\n",
        "\n",
        "def extract_numbers(text):\n",
        "    text = text.lower()\n",
        "    match = re.findall(r\"\\d+\", text)\n",
        "    nums = [int(n) for n in match] if match else []\n",
        "    if \"million\" in text and nums:\n",
        "        nums = [nums[0] * 1_000_000]\n",
        "    if \"thousand\" in text and nums:\n",
        "        nums = [nums[0] * 1000]\n",
        "    return nums\n",
        "\n",
        "def parse_cross_condition(sentence):\n",
        "    s = normalize_text(sentence)\n",
        "\n",
        "    # check if sentence contains \"crosses above\"\n",
        "    if \"crosses above\" in s or \"cross above\" in s:\n",
        "        operator = \"crosses_above\"\n",
        "\n",
        "        # LEFT side → always \"close\" when someone says price\n",
        "        left = \"close\"\n",
        "\n",
        "        # RIGHT side: yesterday's high, yesterday high\n",
        "        if \"yesterday\" in s and \"high\" in s:\n",
        "            right = \"high[1]\"\n",
        "        elif \"yesterday\" in s and \"low\" in s:\n",
        "            right = \"low[1]\"\n",
        "        else:\n",
        "            right = None\n",
        "\n",
        "        if right:\n",
        "            return {\n",
        "                \"left\": left,\n",
        "                \"operator\": operator,\n",
        "                \"right\": right\n",
        "            }\n",
        "\n",
        "    return None\n",
        "\n",
        "def parse_one_condition(sentence):\n",
        "    \"\"\"\n",
        "    Ek condition ko JSON me convert karo.\n",
        "    - \"close price is above the 20-day moving average\"\n",
        "    - \"volume is above 1 million\"\n",
        "    - \"rsi(14) is below 30\"\n",
        "    \"\"\"\n",
        "    rule = parse_cross_condition(sentence)\n",
        "    if rule:\n",
        "     return rule\n",
        "\n",
        "    s = normalize_text(sentence)\n",
        "\n",
        "    left = None\n",
        "    op = None\n",
        "    right = None\n",
        "\n",
        "    # 1) OPERATOR detect karo\n",
        "    if \"above\" in s or \"greater than\" in s:\n",
        "        op = \">\"\n",
        "    elif \"below\" in s or \"less than\" in s:\n",
        "        op = \"<\"\n",
        "    elif \"equal\" in s:\n",
        "        op = \"==\"\n",
        "\n",
        "    # 2) Special case: RSI\n",
        "    if \"rsi\" in s:\n",
        "        # numbers: e.g. \"rsi(14) is below 30\" -> [14, 30]\n",
        "        nums = re.findall(r\"\\d+\", s)\n",
        "        period = int(nums[0]) if len(nums) >= 1 else 14\n",
        "        # threshold last number hoga (e.g. 30)\n",
        "        threshold = int(nums[-1]) if len(nums) >= 2 else 30\n",
        "\n",
        "        left = f\"rsi(close,{period})\"\n",
        "        right = threshold\n",
        "\n",
        "        return {\n",
        "            \"left\": left,\n",
        "            \"operator\": op,\n",
        "            \"right\": right\n",
        "        }\n",
        "\n",
        "    # 3) LEFT side: close / volume (non-RSI case)\n",
        "    if \"close\" in s or \"price\" in s:\n",
        "        left = \"close\"\n",
        "    elif \"volume\" in s:\n",
        "        left = \"volume\"\n",
        "\n",
        "    # 4) RIGHT side KE LIYE:\n",
        "    #    (a) moving average\n",
        "    if \"moving average\" in s or \"ma\" in s:\n",
        "        nums = extract_numbers(s)\n",
        "        period = nums[0] if nums else 20\n",
        "        right = f\"sma({left},{period})\"\n",
        "\n",
        "    #    (b) plain number (e.g. \"1 million\")\n",
        "    if right is None:\n",
        "        nums = extract_numbers(s)\n",
        "        if nums:\n",
        "            right = nums[0]\n",
        "\n",
        "    if left and op and right is not None:\n",
        "        return {\"left\": left, \"operator\": op, \"right\": right}\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def nl_to_json_rules(text):\n",
        "    t = normalize_text(text)\n",
        "\n",
        "    is_entry = any(word in t for word in [\"buy\", \"enter\", \"trigger entry\"])\n",
        "    is_exit = any(word in t for word in [\"exit\", \"sell\"])\n",
        "\n",
        "    entry_rules = []\n",
        "    exit_rules = []\n",
        "\n",
        "    parts = re.split(r\"\\band\\b\", t)\n",
        "\n",
        "    for part in parts:\n",
        "        rule = parse_one_condition(part)\n",
        "        if rule:\n",
        "            if is_exit:\n",
        "                exit_rules.append(rule)\n",
        "            else:\n",
        "                entry_rules.append(rule)\n",
        "\n",
        "    return {\n",
        "        \"entry\": entry_rules,\n",
        "        \"exit\": exit_rules\n",
        "    }\n",
        "\n",
        "nl_to_json_rules(\"Exit when RSI(14) is below 30.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRBzEsVyvYms",
        "outputId": "064263f5-d3b9-4518-d8b1-b6d7d6952418"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'entry': [],\n",
              " 'exit': [{'left': 'rsi(close,14)', 'operator': '<', 'right': 30}]}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nl_to_json_rules(\"Buy when the close price is above the 20-day moving average and volume is above 1 million.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHL0a2N1ftm0",
        "outputId": "c6196c08-04ac-4a51-ddd5-f10dc2d7644f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'entry': [{'left': 'close', 'operator': '>', 'right': 'sma(close,20)'},\n",
              "  {'left': 'volume', 'operator': '>', 'right': 1000000}],\n",
              " 'exit': []}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_cross_condition(sentence):\n",
        "    s = normalize_text(sentence)\n",
        "\n",
        "    # check if sentence contains \"crosses above\"\n",
        "    if \"crosses above\" in s or \"cross above\" in s:\n",
        "        operator = \"crosses_above\"\n",
        "\n",
        "        # LEFT side → always \"close\" when someone says price\n",
        "        left = \"close\"\n",
        "\n",
        "        # RIGHT side: yesterday's high, yesterday high\n",
        "        if \"yesterday\" in s and \"high\" in s:\n",
        "            right = \"high[1]\"\n",
        "        elif \"yesterday\" in s and \"low\" in s:\n",
        "            right = \"low[1]\"\n",
        "        else:\n",
        "            right = None\n",
        "\n",
        "        if right:\n",
        "            return {\n",
        "                \"left\": left,\n",
        "                \"operator\": operator,\n",
        "                \"right\": right\n",
        "            }\n",
        "\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "dBSj5zGQxqm8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nl_to_json_rules(\"Enter when price crosses above yesterday’s high.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btpBr-1Ev-mU",
        "outputId": "39cebdf6-4b85-404e-ce9f-744b9cd15c22"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'entry': [{'left': 'close', 'operator': 'crosses_above', 'right': 'high[1]'}],\n",
              " 'exit': []}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nl_to_json_rules(\"Trigger entry when volume increases by more than 30 percent compared to last week.\")\n"
      ],
      "metadata": {
        "id": "mdGYeQz2yE2-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0725ee86-4cec-4612-a826-1e8cec1b8319"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'entry': [], 'exit': []}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_percent_last_week(sentence):\n",
        "    s = normalize_text(sentence)\n",
        "\n",
        "    # Check percent increase pattern\n",
        "    if \"percent\" in s and (\"increase\" in s or \"increases\" in s):\n",
        "        # extract percent number\n",
        "        nums = re.findall(r\"\\d+\", s)\n",
        "        percent = int(nums[0]) if nums else None\n",
        "\n",
        "        if percent is None:\n",
        "            return None\n",
        "\n",
        "        # detect left side (volume)\n",
        "        if \"volume\" in s:\n",
        "            left = \"volume\"\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "        # detect \"last week\" -> 7 day lookback\n",
        "        if \"last week\" in s:\n",
        "            base = \"volume[7]\"\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "        multiplier = 1 + percent / 100\n",
        "\n",
        "        right = f\"{base} * {multiplier}\"\n",
        "\n",
        "        return {\n",
        "            \"left\": left,\n",
        "            \"operator\": \">\",\n",
        "            \"right\": right\n",
        "        }\n",
        "\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "JwL1DVjGVu6K"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nl_to_json_rules(\"Trigger entry when volume increases by more than 30 percent compared to last week.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9aclfPzV1CI",
        "outputId": "7d8a2765-9260-4902-8c57-440482cb81f4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'entry': [], 'exit': []}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_one_condition(sentence):\n",
        "    s = normalize_text(sentence)\n",
        "\n",
        "    # 1) Percent + last week rule\n",
        "    rule = parse_percent_last_week(sentence)\n",
        "    if rule:\n",
        "        return rule\n",
        "\n",
        "    # 2) Cross above rule\n",
        "    rule = parse_cross_condition(sentence)\n",
        "    if rule:\n",
        "        return rule\n",
        "\n",
        "    # 3) RSI rule\n",
        "    if \"rsi\" in s:\n",
        "        nums = re.findall(r\"\\d+\", s)\n",
        "        period = int(nums[0]) if len(nums) >= 1 else 14\n",
        "        threshold = int(nums[-1]) if len(nums) >= 2 else 30\n",
        "\n",
        "        # operator detection\n",
        "        if \"below\" in s:\n",
        "            op = \"<\"\n",
        "        elif \"above\" in s:\n",
        "            op = \">\"\n",
        "        else:\n",
        "            op = None\n",
        "\n",
        "        return {\n",
        "            \"left\": f\"rsi(close,{period})\",\n",
        "            \"operator\": op,\n",
        "            \"right\": threshold\n",
        "        }\n",
        "\n",
        "    # 4) Basic comparisons (close, volume, SMA)\n",
        "    left = None\n",
        "    op = None\n",
        "    right = None\n",
        "\n",
        "    if \"close\" in s or \"price\" in s:\n",
        "        left = \"close\"\n",
        "    elif \"volume\" in s:\n",
        "        left = \"volume\"\n",
        "\n",
        "    if \"above\" in s:\n",
        "        op = \">\"\n",
        "    elif \"below\" in s:\n",
        "        op = \"<\"\n",
        "    elif \"equal\" in s:\n",
        "        op = \"==\"\n",
        "\n",
        "    # moving average\n",
        "    if \"moving average\" in s or \"ma\" in s:\n",
        "        nums = extract_numbers(s)\n",
        "        period = nums[0] if nums else 20\n",
        "        right = f\"sma({left},{period})\"\n",
        "\n",
        "    # plain numeric\n",
        "    if right is None:\n",
        "        nums = extract_numbers(s)\n",
        "        if nums:\n",
        "            right = nums[0]\n",
        "\n",
        "    if left and op and right is not None:\n",
        "        return {\"left\": left, \"operator\": op, \"right\": right}\n",
        "\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "c93g1jqrV4pG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nl_to_json_rules(\"Trigger entry when volume increases by more than 30 percent compared to last week.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuBe1cviWj0w",
        "outputId": "cea8769b-7bbe-4988-c459-1ab8a2c5d348"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'entry': [{'left': 'volume', 'operator': '>', 'right': 'volume[7] * 1.3'}],\n",
              " 'exit': []}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DSL Parser + AST Construction\n"
      ],
      "metadata": {
        "id": "mp8GfZY6WmTP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lark\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtG3T0zJXpw2",
        "outputId": "b5be97b2-d013-4569-e8d8-c2ac2dda85b1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lark in /usr/local/lib/python3.12/dist-packages (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lark import Lark, Transformer, v_args\n",
        "\n",
        "# -------------------------\n",
        "# DSL GRAMMAR\n",
        "# -------------------------\n",
        "dsl_grammar = r\"\"\"\n",
        "    start: entry exit?\n",
        "\n",
        "    entry: \"ENTRY:\" expr\n",
        "    exit: \"EXIT:\" expr\n",
        "\n",
        "    ?expr: expr \"AND\" expr   -> and_op\n",
        "         | expr \"OR\" expr    -> or_op\n",
        "         | condition\n",
        "         | \"(\" expr \")\"\n",
        "\n",
        "    ?condition: comparison\n",
        "              | cross_above\n",
        "              | cross_below\n",
        "\n",
        "    comparison: series OP value\n",
        "\n",
        "    cross_above: series \"crosses_above\" series\n",
        "    cross_below: series \"crosses_below\" series\n",
        "\n",
        "    series: CNAME (\"[\" NUMBER \"]\")?\n",
        "\n",
        "    indicator: CNAME \"(\" series \",\" NUMBER \")\"\n",
        "\n",
        "    value: NUMBER\n",
        "         | indicator\n",
        "         | series\n",
        "\n",
        "    OP: \">\" | \"<\" | \">=\" | \"<=\" | \"==\"\n",
        "\n",
        "    %import common.CNAME\n",
        "    %import common.NUMBER\n",
        "    %import common.WS\n",
        "    %ignore WS\n",
        "\"\"\"\n",
        "\n",
        "# Create parser\n",
        "dsl_parser = Lark(dsl_grammar, start=\"start\")\n"
      ],
      "metadata": {
        "id": "axHVtWWTXvWZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree = dsl_parser.parse(\"ENTRY: close crosses_above high[1] AND volume > 1000000\")\n",
        "print(tree.pretty())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0lSAOIVX0UH",
        "outputId": "58597baa-a080-45fa-940b-41c3c92629e1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start\n",
            "  entry\n",
            "    and_op\n",
            "      cross_above\n",
            "        series\tclose\n",
            "        series\n",
            "          high\n",
            "          1\n",
            "      comparison\n",
            "        series\tvolume\n",
            "        >\n",
            "        value\t1000000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ats builder"
      ],
      "metadata": {
        "id": "XhV2Vte-X3Ml"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DSLtoAST(Transformer):\n",
        "\n",
        "    def entry(self, items):\n",
        "        return (\"entry\", items[0])\n",
        "\n",
        "    def exit(self, items):\n",
        "        return (\"exit\", items[0])\n",
        "\n",
        "    def and_op(self, items):\n",
        "        return {\n",
        "            \"type\": \"and\",\n",
        "            \"left\": items[0],\n",
        "            \"right\": items[1]\n",
        "        }\n",
        "\n",
        "    def or_op(self, items):\n",
        "        return {\n",
        "            \"type\": \"or\",\n",
        "            \"left\": items[0],\n",
        "            \"right\": items[1]\n",
        "        }\n",
        "\n",
        "    def comparison(self, items):\n",
        "        return {\n",
        "            \"type\": \"comparison\",\n",
        "            \"left\": items[0],\n",
        "            \"operator\": items[1].value,\n",
        "            \"right\": items[2]\n",
        "        }\n",
        "\n",
        "    def cross_above(self, items):\n",
        "        return {\n",
        "            \"type\": \"cross\",\n",
        "            \"direction\": \"above\",\n",
        "            \"left\": items[0],\n",
        "            \"right\": items[1]\n",
        "        }\n",
        "\n",
        "    def cross_below(self, items):\n",
        "        return {\n",
        "            \"type\": \"cross\",\n",
        "            \"direction\": \"below\",\n",
        "            \"left\": items[0],\n",
        "            \"right\": items[1]\n",
        "        }\n",
        "\n",
        "    def series(self, items):\n",
        "        if len(items) == 2:\n",
        "            return f\"{items[0]}[{items[1]}]\"\n",
        "        return items[0].value\n",
        "\n",
        "    def indicator(self, items):\n",
        "        return {\n",
        "            \"type\": \"indicator\",\n",
        "            \"name\": items[0].value.lower(),\n",
        "            \"series\": items[1],\n",
        "            \"period\": int(items[2])\n",
        "        }\n",
        "\n",
        "    def value(self, items):\n",
        "        if len(items) == 1:\n",
        "            return items[0]\n",
        "        return items\n"
      ],
      "metadata": {
        "id": "fjCU2dxGX7kL"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dsl = \"ENTRY: close crosses_above high[1] AND volume > 1000000\"\n",
        "tree = dsl_parser.parse(dsl)\n",
        "ast_transformer = DSLtoAST()\n",
        "ast = ast_transformer.transform(tree)\n",
        "\n",
        "ast\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSLRx7LZX9P0",
        "outputId": "861afc03-b10d-49b0-fd43-e22257c9678f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tree(Token('RULE', 'start'), [('entry', {'type': 'and', 'left': {'type': 'cross', 'direction': 'above', 'left': 'close', 'right': 'high[1]'}, 'right': {'type': 'comparison', 'left': 'volume', 'operator': '>', 'right': Token('NUMBER', '1000000')}})])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_final_ast(dsl_text):\n",
        "    tree = dsl_parser.parse(dsl_text)\n",
        "    ast_transformer = DSLtoAST()\n",
        "    transformed = ast_transformer.transform(tree)\n",
        "\n",
        "    final_ast = {\"entry\": [], \"exit\": []}\n",
        "\n",
        "    # transformed is a Tree: children contain ('entry', ruleAST) / ('exit', ruleAST)\n",
        "    for item in transformed.children:\n",
        "        section, ast = item\n",
        "        if section == \"entry\":\n",
        "            final_ast[\"entry\"].append(ast)\n",
        "        elif section == \"exit\":\n",
        "            final_ast[\"exit\"].append(ast)\n",
        "\n",
        "    return final_ast\n"
      ],
      "metadata": {
        "id": "TvJOuT0JX_XQ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dsl = \"ENTRY: close crosses_above high[1] AND volume > 1000000\"\n",
        "print(build_final_ast(dsl))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ody2ZIFaYY40",
        "outputId": "9822773e-dc6b-4efc-9d9b-1e05d68f1b62"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'entry': [{'type': 'and', 'left': {'type': 'cross', 'direction': 'above', 'left': 'close', 'right': 'high[1]'}, 'right': {'type': 'comparison', 'left': 'volume', 'operator': '>', 'right': Token('NUMBER', '1000000')}}], 'exit': []}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#AST → Python Code Generator"
      ],
      "metadata": {
        "id": "FkFk0GJjYav4"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        " \"type\": \"and\",\n",
        " \"left\": {\n",
        "     \"type\": \"cross\",\n",
        "     \"direction\": \"above\",\n",
        "     \"left\": \"close\",\n",
        "     \"right\": \"high[1]\"\n",
        " },\n",
        " \"right\": {\n",
        "     \"type\": \"comparison\",\n",
        "     \"left\": \"volume\",\n",
        "     \"operator\": \">\",\n",
        "     \"right\": 1000000\n",
        " }\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5t7PmXCY1RR",
        "outputId": "04d36c76-9a46-43c7-ee54-1024caaf8bb5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'type': 'and',\n",
              " 'left': {'type': 'cross',\n",
              "  'direction': 'above',\n",
              "  'left': 'close',\n",
              "  'right': 'high[1]'},\n",
              " 'right': {'type': 'comparison',\n",
              "  'left': 'volume',\n",
              "  'operator': '>',\n",
              "  'right': 1000000}}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Comparison Nodes"
      ],
      "metadata": {
        "id": "lKg9-nRdZAIt"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        " \"type\": \"comparison\",\n",
        " \"left\": \"close\",\n",
        " \"operator\": \">\",\n",
        " \"right\": 1000000\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoHXtGp2Y1xs",
        "outputId": "6f61ca72-f3e4-4fc1-9eae-81bb53566cfe"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'type': 'comparison', 'left': 'close', 'operator': '>', 'right': 1000000}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Indicator Nodes"
      ],
      "metadata": {
        "id": "OHqxG4ctY6IC"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        " \"type\": \"indicator\",\n",
        " \"name\": \"sma\",\n",
        " \"series\": \"close\",\n",
        " \"period\": 20\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7UXDwzrZFQm",
        "outputId": "de81a123-45bf-42b5-90a2-2d76cd8ea0e1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'type': 'indicator', 'name': 'sma', 'series': 'close', 'period': 20}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Cross events"
      ],
      "metadata": {
        "id": "Xalb9j6yZFx8"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dsl_code = \"ENTRY: close crosses_above high[1]\"\n",
        "tree = dsl_parser.parse(dsl_code)\n",
        "print(tree.pretty())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQA8cFhSZIz6",
        "outputId": "244951af-a104-4d68-c6d0-417cb30737fe"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start\n",
            "  entry\n",
            "    cross_above\n",
            "      series\tclose\n",
            "      series\n",
            "        high\n",
            "        1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Final Code Generator Implementation"
      ],
      "metadata": {
        "id": "VWXXLqR_ZK6z"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lark.lexer import Token\n",
        "\n",
        "def generate_python_expr(node):\n",
        "    \"\"\"Convert AST node into pandas expression string\"\"\"\n",
        "\n",
        "    # ---------------------------------------------------\n",
        "    # 1. COMPARISON NODE\n",
        "    # ---------------------------------------------------\n",
        "    if node[\"type\"] == \"comparison\":\n",
        "        left = node[\"left\"]\n",
        "        op = node[\"operator\"]\n",
        "        right = node[\"right\"]\n",
        "\n",
        "        # convert NUMBER tokens → int\n",
        "        if isinstance(right, Token) and right.type == \"NUMBER\":\n",
        "            right = int(right.value)\n",
        "\n",
        "        # ---- LEFT SIDE PROCESSING ----\n",
        "        if isinstance(left, dict) and left.get(\"type\") == \"indicator\":\n",
        "            left_expr = generate_python_expr(left) # Recursively call for indicator\n",
        "        elif isinstance(left, str): # Assume it's a series name (e.g., \"close\", \"volume\")\n",
        "            # This handles series with lag like 'volume[7]'\n",
        "            if \"[\" in left:\n",
        "                series, lag = left.split(\"[\")\n",
        "                lag = lag.replace(\"]\", \"\")\n",
        "                left_expr = f\"df['{series}'].shift({lag})\"\n",
        "            else:\n",
        "                left_expr = f\"df['{left}']\"\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported LHS type for comparison:\", left)\n",
        "\n",
        "        # ---- RIGHT SIDE PROCESSING ----\n",
        "        if isinstance(right, (int, float)):\n",
        "            right_expr = str(right)\n",
        "        elif isinstance(right, str):\n",
        "            # e.g. volume[7] or 'high' or 'close' (if it were in RHS)\n",
        "            if \"[\" in right:\n",
        "                series, lag = right.split(\"[\")\n",
        "                lag = lag.replace(\"]\", \"\")\n",
        "                right_expr = f\"df['{series}'].shift({lag})\"\n",
        "            else:\n",
        "                right_expr = f\"df['{right}']\"\n",
        "        elif isinstance(right, dict) and right.get(\"type\") == \"indicator\":\n",
        "            right_expr = generate_python_expr(right)\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported RHS type for comparison:\", right)\n",
        "\n",
        "        return f\"({left_expr} {op} {right_expr})\"\n",
        "\n",
        "    # ---------------------------------------------------\n",
        "    # 2. INDICATOR NODE\n",
        "    # ---------------------------------------------------\n",
        "    if node[\"type\"] == \"indicator\":\n",
        "        name = node[\"name\"].upper()     # SMA / RSI\n",
        "        series = node[\"series\"]\n",
        "        period = node[\"period\"]\n",
        "        # Ensure series is properly formatted if it's not already a string (e.g., if it's a sub-indicator, though not in current grammar)\n",
        "        if isinstance(series, dict) and series.get(\"type\") == \"indicator\":\n",
        "            series_expr = generate_python_expr(series)\n",
        "        elif isinstance(series, str):\n",
        "            # Handle potential lag in the series definition within an indicator, if applicable\n",
        "            if \"[\" in series:\n",
        "                col, lag = series.split(\"[\")\n",
        "                lag = lag.replace(\"]\", \"\")\n",
        "                series_expr = f\"df['{col}'].shift({lag})\"\n",
        "            else:\n",
        "                series_expr = f\"df['{series}']\"\n",
        "        else:\n",
        "            # Default to direct df access if it's a simple column name\n",
        "            series_expr = f\"df['{series}']\"\n",
        "\n",
        "        return f\"{name}({series_expr}, {period})\"\n",
        "\n",
        "\n",
        "    # ---------------------------------------------------\n",
        "    # 3. CROSS EVENTS\n",
        "    # ---------------------------------------------------\n",
        "    if node[\"type\"] == \"cross\":\n",
        "        left = node[\"left\"]\n",
        "        right = node[\"right\"]\n",
        "\n",
        "        # Recursive call for left and right if they are indicators (though not expected by current grammar)\n",
        "        left_now_expr = generate_python_expr(left) if isinstance(left, dict) else f\"df['{left}']\"\n",
        "        left_prev_expr = generate_python_expr(left) if isinstance(left, dict) else f\"df['{left}'].shift(1)\"\n",
        "\n",
        "        if \"[\" in right:\n",
        "            series_name, lag = right.split(\"[\")\n",
        "            lag = int(lag.replace(\"]\", \"\"))\n",
        "            right_now_expr = f\"df['{series_name}'].shift({lag})\"\n",
        "            right_prev_expr = f\"df['{series_name}'].shift({lag + 1})\"\n",
        "        else:\n",
        "            right_now_expr = generate_python_expr(right) if isinstance(right, dict) else f\"df['{right}']\"\n",
        "            right_prev_expr = generate_python_expr(right) if isinstance(right, dict) else f\"df['{right}'].shift(1)\"\n",
        "\n",
        "        if node[\"direction\"] == \"above\":\n",
        "            return f\"((({left_prev_expr}) <= ({right_prev_expr})) & (({left_now_expr}) > ({right_now_expr})))\"\n",
        "\n",
        "        if node[\"direction\"] == \"below\":\n",
        "            return f\"((({left_prev_expr}) >= ({right_prev_expr})) & (({left_now_expr}) < ({right_now_expr})))\"\n",
        "\n",
        "    # ---------------------------------------------------\n",
        "    # 4. LOGICAL OPERATORS\n",
        "    # ---------------------------------------------------\n",
        "    if node[\"type\"] == \"and\":\n",
        "        left_expr = generate_python_expr(node[\"left\"])\n",
        "        right_expr = generate_python_expr(node[\"right\"])\n",
        "        return f\"({left_expr} & {right_expr})\"\n",
        "\n",
        "    if node[\"type\"] == \"or\":\n",
        "        left_expr = generate_python_expr(node[\"left\"])\n",
        "        right_expr = generate_python_expr(node[\"right\"])\n",
        "        return f\"({left_expr} | {right_expr})\"\n",
        "\n",
        "    # ---------------------------------------------------\n",
        "    # UNKNOWN NODE TYPE\n",
        "    # ---------------------------------------------------\n",
        "    raise ValueError(\"Unknown AST node type:\", node)"
      ],
      "metadata": {
        "id": "-XHleLiHZeHh"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to convert full AST to Python functions"
      ],
      "metadata": {
        "id": "GFD90JxsZekw"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ast_to_python_code(final_ast):\n",
        "    entry_expr = \"\"\n",
        "    exit_expr = \"\"\n",
        "\n",
        "    if final_ast[\"entry\"]:\n",
        "        entry_expr = generate_python_expr(final_ast[\"entry\"][0])\n",
        "    if final_ast[\"exit\"]:\n",
        "        exit_expr = generate_python_expr(final_ast[\"exit\"][0])\n",
        "\n",
        "    code = f\"\"\"\n",
        "def run_strategy(df):\n",
        "    import pandas as pd\n",
        "\n",
        "    signals = pd.DataFrame(index=df.index)\n",
        "    signals['entry'] = {entry_expr}\n",
        "    signals['exit'] = {exit_expr}\n",
        "\n",
        "    return signals\n",
        "\"\"\"\n",
        "    return code\n"
      ],
      "metadata": {
        "id": "22cwqMFCZimZ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dsl = \"ENTRY: close crosses_above high[1] AND volume > 1000000\"\n",
        "ast = build_final_ast(dsl)\n",
        "\n",
        "code = ast_to_python_code(ast)\n",
        "print(code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0lCTIgcZkSt",
        "outputId": "094b1773-f629-412a-e9bd-d76c4f20564f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "def run_strategy(df):\n",
            "    import pandas as pd\n",
            "\n",
            "    signals = pd.DataFrame(index=df.index)\n",
            "    signals['entry'] = ((((df['close'].shift(1)) <= (df['high'].shift(2))) & ((df['close']) > (df['high'].shift(1)))) & (df['volume'] > 1000000))\n",
            "    signals['exit'] = \n",
            "\n",
            "    return signals\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Part 5: Backtest Engine"
      ],
      "metadata": {
        "id": "-NHs3kqzZmLv"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def backtest_signals(df, signals, initial_capital=100000.0, slippage=0.0, commission=0.0):\n",
        "    \"\"\"\n",
        "    Run a simple backtest using boolean entry/exit signals.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): OHLCV dataframe with columns ['open','high','low','close','volume'].\n",
        "        signals (pd.DataFrame): DataFrame with boolean columns 'entry' and 'exit' indexed same as df.\n",
        "        initial_capital (float): starting cash.\n",
        "        slippage (float): per-share slippage to apply on entry/exit prices (absolute).\n",
        "        commission (float): fixed commission per trade.\n",
        "    Returns:\n",
        "        dict: {\n",
        "            'trades': list of trade dicts,\n",
        "            'equity': pd.Series (daily equity curve),\n",
        "            'final_capital': float,\n",
        "            'total_return_pct': float,\n",
        "            'max_drawdown_pct': float,\n",
        "            'num_trades': int\n",
        "        }\n",
        "    \"\"\"\n",
        "    # sanity checks\n",
        "    assert 'entry' in signals.columns and 'exit' in signals.columns, \"signals must have 'entry' and 'exit' columns\"\n",
        "    assert df.shape[0] == signals.shape[0], \"df and signals must have the same number of rows and aligned index\"\n",
        "    # align indices\n",
        "    signals = signals.reindex(df.index)\n",
        "\n",
        "    cash = float(initial_capital)\n",
        "    position = 0.0      # number of shares currently held (0 means flat)\n",
        "    entry_price = None  # price we entered\n",
        "    entry_index = None\n",
        "\n",
        "    trades = []\n",
        "    equity_list = []\n",
        "    equity_index = []\n",
        "\n",
        "    # track last known equity for days before first trade\n",
        "    # iterate rows by index position so we can look at next row for fills\n",
        "    idxs = list(df.index)\n",
        "    n = len(idxs)\n",
        "\n",
        "    for i, idx in enumerate(idxs):\n",
        "        row = df.loc[idx]\n",
        "        # default today's market value of any open position (use close price to mark-to-market)\n",
        "        close_price = float(row['close'])\n",
        "\n",
        "        # 1) If currently flat, check for entry signal at this row\n",
        "        if position == 0:\n",
        "            if signals.loc[idx, 'entry']:\n",
        "                # determine fill price: next open if exists else current close\n",
        "                if i+1 < n:\n",
        "                    fill_idx = idxs[i+1]\n",
        "                    fill_price = float(df.loc[fill_idx, 'open'])\n",
        "                else:\n",
        "                    fill_price = close_price\n",
        "\n",
        "                # apply slippage on entry (assume slippage increases buy price)\n",
        "                buy_price = fill_price + slippage\n",
        "\n",
        "                # calculate number of shares (allow fractional)\n",
        "                shares = cash / buy_price if buy_price > 0 else 0.0\n",
        "                if shares > 0:\n",
        "                    position = shares\n",
        "                    entry_price = buy_price\n",
        "                    entry_index = idx\n",
        "\n",
        "                    # deduct commission\n",
        "                    cash -= commission\n",
        "\n",
        "                    # Note: we keep full cash invested (cash becomes 0), but to avoid tiny rounding issues:\n",
        "                    cash = max(0.0, cash)\n",
        "\n",
        "                    trades.append({\n",
        "                        'entry_index': idx,\n",
        "                        'entry_fill_index': fill_idx if i+1 < n else idx,\n",
        "                        'entry_price': buy_price,\n",
        "                        'exit_index': None,\n",
        "                        'exit_fill_index': None,\n",
        "                        'exit_price': None,\n",
        "                        'shares': shares,\n",
        "                        'pnl': None,\n",
        "                        'return_pct': None\n",
        "                    })\n",
        "\n",
        "        # 2) If in position, check exit signal\n",
        "        elif position > 0:\n",
        "            if signals.loc[idx, 'exit']:\n",
        "                # determine exit fill price (next open if exists else current close)\n",
        "                if i+1 < n:\n",
        "                    fill_idx = idxs[i+1]\n",
        "                    fill_price = float(df.loc[fill_idx, 'open'])\n",
        "                else:\n",
        "                    fill_price = close_price\n",
        "\n",
        "                # apply slippage (assume slippage increases sell price negatively, i.e. lowers proceeds)\n",
        "                sell_price = fill_price - slippage\n",
        "\n",
        "                # compute proceeds\n",
        "                proceeds = position * sell_price\n",
        "\n",
        "                # compute trade PnL = proceeds - cost\n",
        "                cost = position * entry_price\n",
        "                pnl = proceeds - cost - commission  # subtract commission at exit\n",
        "                return_pct = (pnl / cost) if cost != 0 else 0.0\n",
        "\n",
        "                # update cash\n",
        "                cash += proceeds\n",
        "                # ensure cash is float\n",
        "                cash = float(cash)\n",
        "\n",
        "                # record in last trade dict\n",
        "                last_trade = trades[-1]\n",
        "                last_trade['exit_index'] = idx\n",
        "                last_trade['exit_fill_index'] = fill_idx if i+1 < n else idx\n",
        "                last_trade['exit_price'] = sell_price\n",
        "                last_trade['pnl'] = pnl\n",
        "                last_trade['return_pct'] = return_pct\n",
        "\n",
        "                # reset position\n",
        "                position = 0.0\n",
        "                entry_price = None\n",
        "                entry_index = None\n",
        "\n",
        "        # daily equity mark-to-market: cash + position * close\n",
        "        mtm = cash + position * close_price\n",
        "        equity_list.append(mtm)\n",
        "        equity_index.append(idx)\n",
        "\n",
        "    # after loop, if still in position, close at last close price (mark-to-market but also treat as exit)\n",
        "    if position > 0:\n",
        "        last_idx = idxs[-1]\n",
        "        last_close = float(df.loc[last_idx, 'close'])\n",
        "        sell_price = last_close - slippage\n",
        "        proceeds = position * sell_price\n",
        "        cost = trades[-1]['shares'] * trades[-1]['entry_price']\n",
        "        pnl = proceeds - cost - commission\n",
        "        return_pct = (pnl / cost) if cost != 0 else 0.0\n",
        "\n",
        "        # finalize last trade\n",
        "        last_trade = trades[-1]\n",
        "        last_trade['exit_index'] = last_idx\n",
        "        last_trade['exit_fill_index'] = last_idx\n",
        "        last_trade['exit_price'] = sell_price\n",
        "        last_trade['pnl'] = pnl\n",
        "        last_trade['return_pct'] = return_pct\n",
        "\n",
        "        cash += proceeds\n",
        "        position = 0.0\n",
        "        equity_list[-1] = cash  # final equity equals cash after forced close\n",
        "\n",
        "    equity = pd.Series(equity_list, index=equity_index)\n",
        "\n",
        "    # metrics\n",
        "    final_capital = float(equity.iloc[-1]) if len(equity) else float(initial_capital)\n",
        "    total_return_pct = ((final_capital - initial_capital) / initial_capital) * 100.0\n",
        "\n",
        "    # max drawdown calculation\n",
        "    roll_max = equity.cummax()\n",
        "    drawdown = (equity - roll_max) / roll_max\n",
        "    max_drawdown_pct = float(drawdown.min() * 100.0) if not drawdown.empty else 0.0\n",
        "\n",
        "    num_trades = len(trades)\n",
        "    # format trades nicely (round floats)\n",
        "    for t in trades:\n",
        "        # convert indices to str for JSON friendliness if they are timestamps\n",
        "        t['entry_index'] = str(t['entry_index'])\n",
        "        t['exit_index'] = str(t['exit_index']) if t['exit_index'] is not None else None\n",
        "        t['pnl'] = float(t['pnl']) if t['pnl'] is not None else None\n",
        "        t['return_pct'] = float(t['return_pct']) * 100.0 if t['return_pct'] is not None else None\n",
        "        t['entry_price'] = float(t['entry_price']) if t['entry_price'] is not None else None\n",
        "        t['exit_price'] = float(t['exit_price']) if t['exit_price'] is not None else None\n",
        "        t['shares'] = float(t.get('shares', 0.0))\n",
        "\n",
        "    results = {\n",
        "        'trades': trades,\n",
        "        'equity': equity,\n",
        "        'final_capital': final_capital,\n",
        "        'total_return_pct': total_return_pct,\n",
        "        'max_drawdown_pct': max_drawdown_pct,\n",
        "        'num_trades': num_trades\n",
        "    }\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "VMPr2BOEZ3sY"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining df\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "dates = pd.date_range(\"2023-01-01\", periods=100)\n",
        "prices = np.linspace(100, 150, 100) + np.random.normal(0, 2, 100)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"open\": prices + np.random.normal(0, 1, 100),\n",
        "    \"high\": prices + np.random.normal(1, 1, 100),\n",
        "    \"low\": prices - np.random.normal(1, 1, 100),\n",
        "    \"close\": prices,\n",
        "    \"volume\": np.random.randint(10000, 20000, size=100)\n",
        "}, index=dates)\n"
      ],
      "metadata": {
        "id": "8iTtk-atalUy"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining signals\n",
        "signals = pd.DataFrame(index=df.index)\n",
        "signals[\"entry\"] = df[\"close\"] > df[\"close\"].shift(1)   # dummy example\n",
        "signals[\"exit\"] = df[\"close\"] < df[\"close\"].shift(1)    # dummy example\n"
      ],
      "metadata": {
        "id": "DZcQMuiaasaZ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df: your OHLCV DataFrame\n",
        "# signals: DataFrame with columns ['entry','exit'] (booleans), same index as df\n",
        "\n",
        "out = backtest_signals(df, signals, initial_capital=100000, slippage=0.0, commission=0.0)\n",
        "\n",
        "print(\"Total Return (pct):\", out['total_return_pct'])\n",
        "print(\"Max Drawdown (pct):\", out['max_drawdown_pct'])\n",
        "print(\"Number of trades:\", out['num_trades'])\n",
        "print(\"Trades log:\")\n",
        "for t in out['trades']:\n",
        "    print(t)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXZ4MavYZ6pV",
        "outputId": "77a3b0e6-3568-47c9-8d85-7859da53bd21"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Return (pct): 3979569165673.9907\n",
            "Max Drawdown (pct): -2.140356181356539\n",
            "Number of trades: 35\n",
            "Trades log:\n",
            "{'entry_index': '2023-01-03 00:00:00', 'entry_fill_index': Timestamp('2023-01-04 00:00:00'), 'entry_price': 106.96633462171245, 'exit_index': '2023-01-05 00:00:00', 'exit_fill_index': Timestamp('2023-01-06 00:00:00'), 'exit_price': 102.514317951149, 'shares': 934.873578249185, 'pnl': -4162.07275523468, 'return_pct': -4.1620727552346795}\n",
            "{'entry_index': '2023-01-07 00:00:00', 'entry_fill_index': Timestamp('2023-01-08 00:00:00'), 'entry_price': 102.48518430731738, 'exit_index': '2023-01-08 00:00:00', 'exit_fill_index': Timestamp('2023-01-09 00:00:00'), 'exit_price': 105.75690836329731, 'shares': 1910.890130787252, 'pnl': 6251.905209231307, 'return_pct': 3.192387346613125}\n",
            "{'entry_index': '2023-01-09 00:00:00', 'entry_fill_index': Timestamp('2023-01-10 00:00:00'), 'entry_price': 106.84716634076572, 'exit_index': '2023-01-11 00:00:00', 'exit_fill_index': Timestamp('2023-01-12 00:00:00'), 'exit_price': 109.3701472277569, 'shares': 3724.270594408262, 'pnl': 9396.263527675299, 'return_pct': 2.361298828407555}\n",
            "{'entry_index': '2023-01-12 00:00:00', 'entry_fill_index': Timestamp('2023-01-13 00:00:00'), 'entry_price': 106.72145582584534, 'exit_index': '2023-01-13 00:00:00', 'exit_fill_index': Timestamp('2023-01-14 00:00:00'), 'exit_price': 108.71907155174127, 'shares': 7545.359803180148, 'pnl': 15072.729400375742, 'return_pct': 1.8718032943214065}\n",
            "{'entry_index': '2023-01-15 00:00:00', 'entry_fill_index': Timestamp('2023-01-16 00:00:00'), 'entry_price': 109.04556262630251, 'exit_index': '2023-01-18 00:00:00', 'exit_fill_index': Timestamp('2023-01-19 00:00:00'), 'exit_price': 110.33112386455697, 'shares': 14907.312650782496, 'pnl': 19164.263310386334, 'return_pct': 1.1789211842210028}\n",
            "{'entry_index': '2023-01-19 00:00:00', 'entry_fill_index': Timestamp('2023-01-20 00:00:00'), 'entry_price': 108.80997478892267, 'exit_index': '2023-01-20 00:00:00', 'exit_fill_index': Timestamp('2023-01-21 00:00:00'), 'exit_price': 105.37145600049757, 'shares': 30055.303846507897, 'pnl': -103345.72696804255, 'return_pct': -3.1601135788289465}\n",
            "{'entry_index': '2023-01-22 00:00:00', 'entry_fill_index': Timestamp('2023-01-23 00:00:00'), 'entry_price': 113.13822168303619, 'exit_index': '2023-01-24 00:00:00', 'exit_fill_index': Timestamp('2023-01-25 00:00:00'), 'exit_price': 115.96615350945598, 'shares': 56897.5531424764, 'pnl': 160902.40137701947, 'return_pct': 2.499537101035937}\n",
            "{'entry_index': '2023-01-25 00:00:00', 'entry_fill_index': Timestamp('2023-01-26 00:00:00'), 'entry_price': 109.56789673673744, 'exit_index': '2023-01-26 00:00:00', 'exit_fill_index': Timestamp('2023-01-27 00:00:00'), 'exit_price': 112.78767661419438, 'shares': 118971.694729246, 'pnl': 383062.6686761752, 'return_pct': 2.9386161214659507}\n",
            "{'entry_index': '2023-01-27 00:00:00', 'entry_fill_index': Timestamp('2023-01-28 00:00:00'), 'entry_price': 115.11125966479132, 'exit_index': '2023-01-31 00:00:00', 'exit_fill_index': Timestamp('2023-02-01 00:00:00'), 'exit_price': 116.95213988706182, 'shares': 229812.61321515124, 'pnl': 423057.4944960736, 'return_pct': 1.5992182064823415}\n",
            "{'entry_index': '2023-02-01 00:00:00', 'entry_fill_index': Timestamp('2023-02-02 00:00:00'), 'entry_price': 113.71171200569857, 'exit_index': '2023-02-02 00:00:00', 'exit_fill_index': Timestamp('2023-02-03 00:00:00'), 'exit_price': 112.73690428849316, 'shares': 469002.6677281095, 'pnl': -457187.4198912829, 'return_pct': -0.8572623699101038}\n",
            "{'entry_index': '2023-02-04 00:00:00', 'entry_fill_index': Timestamp('2023-02-05 00:00:00'), 'entry_price': 118.66589890992215, 'exit_index': '2023-02-08 00:00:00', 'exit_fill_index': Timestamp('2023-02-09 00:00:00'), 'exit_price': 117.99930268708853, 'shares': 894991.7888873358, 'pnl': -596598.1459394097, 'return_pct': -0.5617420244207083}\n",
            "{'entry_index': '2023-02-09 00:00:00', 'entry_fill_index': Timestamp('2023-02-10 00:00:00'), 'entry_price': 116.61365667918041, 'exit_index': '2023-02-10 00:00:00', 'exit_fill_index': Timestamp('2023-02-11 00:00:00'), 'exit_price': 118.3064265339773, 'shares': 1816368.8385779485, 'pnl': 3074694.4151372015, 'return_pct': 1.4516051575793822}\n",
            "{'entry_index': '2023-02-13 00:00:00', 'entry_fill_index': Timestamp('2023-02-14 00:00:00'), 'entry_price': 123.58606263358286, 'exit_index': '2023-02-14 00:00:00', 'exit_fill_index': Timestamp('2023-02-15 00:00:00'), 'exit_price': 122.79560361104078, 'shares': 3452666.988587821, 'pnl': -2729191.7729623914, 'return_pct': -0.6396020762354724}\n",
            "{'entry_index': '2023-02-15 00:00:00', 'entry_fill_index': Timestamp('2023-02-16 00:00:00'), 'entry_price': 119.81391028677923, 'exit_index': '2023-02-16 00:00:00', 'exit_fill_index': Timestamp('2023-02-17 00:00:00'), 'exit_price': 126.40937073713341, 'shares': 7099958.958020429, 'pnl': 46827498.50676155, 'return_pct': 5.504753525335815}\n",
            "{'entry_index': '2023-02-17 00:00:00', 'entry_fill_index': Timestamp('2023-02-18 00:00:00'), 'entry_price': 119.69872113679682, 'exit_index': '2023-02-18 00:00:00', 'exit_fill_index': Timestamp('2023-02-19 00:00:00'), 'exit_price': 123.8604095822321, 'shares': 14604794.213139677, 'pnl': 60780603.324783325, 'return_pct': 3.4768027643997272}\n",
            "{'entry_index': '2023-02-19 00:00:00', 'entry_fill_index': Timestamp('2023-02-20 00:00:00'), 'entry_price': 123.39335052481327, 'exit_index': '2023-02-20 00:00:00', 'exit_fill_index': Timestamp('2023-02-21 00:00:00'), 'exit_price': 128.24472347494364, 'shares': 28827574.320281524, 'pnl': 139853314.27528667, 'return_pct': 3.9316324011761097}\n",
            "{'entry_index': '2023-02-21 00:00:00', 'entry_fill_index': Timestamp('2023-02-22 00:00:00'), 'entry_price': 124.49626116544009, 'exit_index': '2023-02-22 00:00:00', 'exit_fill_index': Timestamp('2023-02-23 00:00:00'), 'exit_price': 123.57997386077292, 'shares': 58267736.01177207, 'pnl': -53389986.77928448, 'return_pct': -0.735995841232157}\n",
            "{'entry_index': '2023-02-24 00:00:00', 'entry_fill_index': Timestamp('2023-02-25 00:00:00'), 'entry_price': 127.97096323247649, 'exit_index': '2023-02-26 00:00:00', 'exit_fill_index': Timestamp('2023-02-27 00:00:00'), 'exit_price': 128.31289107499492, 'shares': 112954065.5800374, 'pnl': 38622139.947467804, 'return_pct': 0.2671917393458039}\n",
            "{'entry_index': '2023-02-27 00:00:00', 'entry_fill_index': Timestamp('2023-02-28 00:00:00'), 'entry_price': 126.87681645315627, 'exit_index': '2023-02-28 00:00:00', 'exit_fill_index': Timestamp('2023-03-01 00:00:00'), 'exit_price': 128.6346774212611, 'shares': 228160700.24296972, 'pnl': 401074789.4125824, 'return_pct': 1.3854863459265958}\n",
            "{'entry_index': '2023-03-01 00:00:00', 'entry_fill_index': Timestamp('2023-03-02 00:00:00'), 'entry_price': 128.4600769567861, 'exit_index': '2023-03-02 00:00:00', 'exit_fill_index': Timestamp('2023-03-03 00:00:00'), 'exit_price': 132.0185065388167, 'shares': 453819449.1517052, 'pnl': 1614884552.7622452, 'return_pct': 2.7700665189758698}\n",
            "{'entry_index': '2023-03-03 00:00:00', 'entry_fill_index': Timestamp('2023-03-04 00:00:00'), 'entry_price': 130.63625955596817, 'exit_index': '2023-03-04 00:00:00', 'exit_fill_index': Timestamp('2023-03-05 00:00:00'), 'exit_price': 128.45316785490365, 'shares': 904880832.3170521, 'pnl': -1975437835.4837036, 'return_pct': -1.671122327357524}\n",
            "{'entry_index': '2023-03-06 00:00:00', 'entry_fill_index': Timestamp('2023-03-07 00:00:00'), 'entry_price': 132.86908393226784, 'exit_index': '2023-03-07 00:00:00', 'exit_fill_index': Timestamp('2023-03-08 00:00:00'), 'exit_price': 129.0727212920117, 'shares': 1764481621.9219987, 'pnl': -6698612108.88324, 'return_pct': -2.857220451818122}\n",
            "{'entry_index': '2023-03-09 00:00:00', 'entry_fill_index': Timestamp('2023-03-10 00:00:00'), 'entry_price': 133.71686740702017, 'exit_index': '2023-03-10 00:00:00', 'exit_fill_index': Timestamp('2023-03-11 00:00:00'), 'exit_price': 135.26931825200197, 'shares': 3456493636.845757, 'pnl': 5366036467.195374, 'return_pct': 1.1609985150611486}\n",
            "{'entry_index': '2023-03-11 00:00:00', 'entry_fill_index': Timestamp('2023-03-12 00:00:00'), 'entry_price': 137.73257530167126, 'exit_index': '2023-03-13 00:00:00', 'exit_fill_index': Timestamp('2023-03-14 00:00:00'), 'exit_price': 139.49926834462568, 'shares': 6750393195.6069355, 'pnl': 11925872695.88562, 'return_pct': 1.2826980393598881}\n",
            "{'entry_index': '2023-03-14 00:00:00', 'entry_fill_index': Timestamp('2023-03-15 00:00:00'), 'entry_price': 133.74800963467942, 'exit_index': '2023-03-15 00:00:00', 'exit_fill_index': Timestamp('2023-03-16 00:00:00'), 'exit_price': 137.144177814308, 'shares': 13992162994.179531, 'pnl': 47519738725.00903, 'return_pct': 2.53922894920448}\n",
            "{'entry_index': '2023-03-16 00:00:00', 'entry_fill_index': Timestamp('2023-03-17 00:00:00'), 'entry_price': 137.19076221518887, 'exit_index': '2023-03-17 00:00:00', 'exit_fill_index': Timestamp('2023-03-18 00:00:00'), 'exit_price': 135.8388344213008, 'shares': 27628446547.22985, 'pnl': -37351664789.15137, 'return_pct': -0.9854364623818742}\n",
            "{'entry_index': '2023-03-18 00:00:00', 'entry_fill_index': Timestamp('2023-03-19 00:00:00'), 'entry_price': 137.04163978160986, 'exit_index': '2023-03-22 00:00:00', 'exit_fill_index': Timestamp('2023-03-23 00:00:00'), 'exit_price': 141.33579258958127, 'shares': 55044464065.84269, 'pnl': 236369339931.62012, 'return_pct': 3.1334657223998468}\n",
            "{'entry_index': '2023-03-23 00:00:00', 'entry_fill_index': Timestamp('2023-03-24 00:00:00'), 'entry_price': 141.70184789076947, 'exit_index': '2023-03-24 00:00:00', 'exit_fill_index': Timestamp('2023-03-25 00:00:00'), 'exit_price': 136.62330139441306, 'shares': 108136462586.63744, 'pnl': -549176053197.74414, 'return_pct': -3.5839663151543375}\n",
            "{'entry_index': '2023-03-26 00:00:00', 'entry_fill_index': Timestamp('2023-03-27 00:00:00'), 'entry_price': 145.11901362574733, 'exit_index': '2023-03-28 00:00:00', 'exit_fill_index': Timestamp('2023-03-29 00:00:00'), 'exit_price': 143.6317093470302, 'shares': 207395959637.76266, 'pnl': -308460898157.8867, 'return_pct': -1.024885879222401}\n",
            "{'entry_index': '2023-03-31 00:00:00', 'entry_fill_index': Timestamp('2023-04-01 00:00:00'), 'entry_price': 143.35533465087568, 'exit_index': '2023-04-01 00:00:00', 'exit_fill_index': Timestamp('2023-04-02 00:00:00'), 'exit_price': 148.67153696971002, 'shares': 417743318955.5262, 'pnl': 2220808000908.922, 'return_pct': 3.7084091302087216}\n",
            "{'entry_index': '2023-04-02 00:00:00', 'entry_fill_index': Timestamp('2023-04-03 00:00:00'), 'entry_price': 146.8419136025727, 'exit_index': '2023-04-03 00:00:00', 'exit_fill_index': Timestamp('2023-04-04 00:00:00'), 'exit_price': 147.7548815449232, 'shares': 830772846676.1516, 'pnl': 758468976390.5938, 'return_pct': 0.6217352525256827}\n",
            "{'entry_index': '2023-04-04 00:00:00', 'entry_fill_index': Timestamp('2023-04-05 00:00:00'), 'entry_price': 148.71075692962805, 'exit_index': '2023-04-05 00:00:00', 'exit_fill_index': Timestamp('2023-04-06 00:00:00'), 'exit_price': 149.22139798495962, 'shares': 1645765398411.441, 'pnl': 840395379873.0, 'return_pct': 0.34337869423475015}\n",
            "{'entry_index': '2023-04-06 00:00:00', 'entry_fill_index': Timestamp('2023-04-07 00:00:00'), 'entry_price': 149.2776390775038, 'exit_index': '2023-04-07 00:00:00', 'exit_fill_index': Timestamp('2023-04-08 00:00:00'), 'exit_price': 153.3851441316744, 'shares': 3284660948971.8135, 'pnl': 13491761449138.5, 'return_pct': 2.7515876319815105}\n",
            "{'entry_index': '2023-04-08 00:00:00', 'entry_fill_index': Timestamp('2023-04-09 00:00:00'), 'entry_price': 151.9120096296374, 'exit_index': '2023-04-09 00:00:00', 'exit_fill_index': Timestamp('2023-04-10 00:00:00'), 'exit_price': 152.1405066763258, 'shares': 6544213503185.439, 'pnl': 1495333458376.25, 'return_pct': 0.1504140767049833}\n",
            "{'entry_index': '2023-04-10 00:00:00', 'entry_fill_index': Timestamp('2023-04-10 00:00:00'), 'entry_price': 150.8039787268894, 'exit_index': '2023-04-10 00:00:00', 'exit_fill_index': Timestamp('2023-04-10 00:00:00'), 'exit_price': 150.8039787268894, 'shares': 13194509851033.545, 'pnl': 0.0, 'return_pct': 0.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 6 – Final Integration / Demo"
      ],
      "metadata": {
        "id": "9WppanGSZ-mn"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# demo.py\n",
        "\n",
        "import pandas as pd\n",
        "from lark import Lark\n",
        "# ------- IMPORT YOUR OWN MODULES HERE -------\n",
        "# from nl_parser import nl_to_json_rules         # Part 1\n",
        "# from dsl_parser import dsl_parser              # Part 3\n",
        "# from ast_builder import DSLtoAST, build_final_ast\n",
        "# from code_generator import ast_to_python_code, generate_python_expr\n",
        "# from backtester import backtest_signals        # Part 5\n",
        "\n",
        "# BUT since your code is in the notebook, we directly call functions:\n",
        "# (Assuming all previous Parts are executed in cells above)\n",
        "\n",
        "# ---------------------------------------------\n",
        "# STEP 1 → Natural Language → DSL\n",
        "# ---------------------------------------------\n",
        "\n",
        "def json_to_dsl(json_rules):\n",
        "    \"\"\"Convert NL → JSON rules into DSL string.\"\"\"\n",
        "    entry_rules = []\n",
        "    exit_rules = []\n",
        "\n",
        "    # Entry\n",
        "    for rule in json_rules[\"entry\"]:\n",
        "        left = rule[\"left\"]\n",
        "        op = rule[\"operator\"]\n",
        "        right = rule[\"right\"]\n",
        "        entry_rules.append(f\"{left} {op} {right}\")\n",
        "\n",
        "    # Exit\n",
        "    for rule in json_rules[\"exit\"]:\n",
        "        left = rule[\"left\"]\n",
        "        op = rule[\"operator\"]\n",
        "        right = rule[\"right\"]\n",
        "        exit_rules.append(f\"{left} {op} {right}\")\n",
        "\n",
        "    dsl = \"\"\n",
        "\n",
        "    if entry_rules:\n",
        "        dsl += \"ENTRY: \" + \" AND \".join(entry_rules) + \"\\n\"\n",
        "\n",
        "    if exit_rules:\n",
        "        dsl += \"EXIT: \" + \" AND \".join(exit_rules)\n",
        "\n",
        "    return dsl.strip()\n",
        "\n",
        "\n",
        "# ---------------------------------------------\n",
        "# STEP 2 → DSL → AST\n",
        "# ---------------------------------------------\n",
        "\n",
        "def parse_dsl_to_ast(dsl_text):\n",
        "    tree = dsl_parser.parse(dsl_text)\n",
        "    transformer = DSLtoAST()\n",
        "    parsed = transformer.transform(tree)\n",
        "    final_ast = {\"entry\": [], \"exit\": []}\n",
        "\n",
        "    for node in parsed.children:\n",
        "        section, ast = node\n",
        "        final_ast[section].append(ast)\n",
        "\n",
        "    return final_ast\n",
        "\n",
        "\n",
        "# ---------------------------------------------\n",
        "# STEP 3 → AST → Python expression\n",
        "# ---------------------------------------------\n",
        "\n",
        "def ast_to_signals(df, ast):\n",
        "    signals = pd.DataFrame(index=df.index)\n",
        "    signals[\"entry\"] = False\n",
        "    signals[\"exit\"] = False\n",
        "\n",
        "    if ast[\"entry\"]:\n",
        "        entry_expr = generate_python_expr(ast[\"entry\"][0])\n",
        "        signals[\"entry\"] = eval(entry_expr)\n",
        "\n",
        "    if ast[\"exit\"]:\n",
        "        exit_expr = generate_python_expr(ast[\"exit\"][0])\n",
        "        signals[\"exit\"] = eval(exit_expr)\n",
        "\n",
        "    signals = signals.fillna(False)\n",
        "    return signals\n",
        "\n",
        "\n",
        "# ---------------------------------------------\n",
        "# FINAL END-TO-END FUNCTION\n",
        "# ---------------------------------------------\n",
        "\n",
        "def run_pipeline(entry_nl, exit_nl, df):\n",
        "    print(\"\\n========================\")\n",
        "    print(\"1. NL → JSON\")\n",
        "    print(\"========================\")\n",
        "    entry_json = nl_to_json_rules(entry_nl)\n",
        "    exit_json = nl_to_json_rules(exit_nl)\n",
        "\n",
        "    json_rules = {\n",
        "        \"entry\": entry_json[\"entry\"],\n",
        "        \"exit\": exit_json[\"exit\"]\n",
        "    }\n",
        "\n",
        "    print(json_rules)\n",
        "\n",
        "    print(\"\\n========================\")\n",
        "    print(\"2. JSON → DSL\")\n",
        "    print(\"========================\")\n",
        "    dsl = json_to_dsl(json_rules)\n",
        "    print(dsl)\n",
        "\n",
        "    print(\"\\n========================\")\n",
        "    print(\"3. DSL → AST\")\n",
        "    print(\"========================\")\n",
        "    ast = parse_dsl_to_ast(dsl)\n",
        "    print(ast)\n",
        "\n",
        "    print(\"\\n========================\")\n",
        "    print(\"4. AST → Python Code → Signals\")\n",
        "    print(\"========================\")\n",
        "    signals = ast_to_signals(df, ast)\n",
        "    print(signals.head())\n",
        "\n",
        "    print(\"\\n========================\")\n",
        "    print(\"5. Running Backtest\")\n",
        "    print(\"========================\")\n",
        "    result = backtest_signals(df, signals)\n",
        "\n",
        "    print(\"\\nFinal Results:\")\n",
        "    print(\"Total Return (%) =\", result[\"total_return_pct\"])\n",
        "    print(\"Max Drawdown (%) =\", result[\"max_drawdown_pct\"])\n",
        "    print(\"Number of Trades =\", result[\"num_trades\"])\n",
        "    print(\"\\nTrades Log:\")\n",
        "    for t in result[\"trades\"]:\n",
        "        print(t)\n",
        "\n",
        "    return result\n",
        "\n"
      ],
      "metadata": {
        "id": "U9qQ3dZHbVzg"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dsl_grammar = r\"\"\"\n",
        "    start: entry exit?\n",
        "\n",
        "    entry: \"ENTRY:\" expr\n",
        "    exit: \"EXIT:\" expr\n",
        "\n",
        "    ?expr: expr \"AND\" expr   -> and_op\n",
        "         | expr \"OR\" expr    -> or_op\n",
        "         | condition\n",
        "         | \"(\" expr \")\"\n",
        "\n",
        "    ?condition: comparison\n",
        "              | cross_above\n",
        "              | cross_below\n",
        "\n",
        "    comparison: operand OP operand\n",
        "\n",
        "    ?operand: indicator\n",
        "            | series\n",
        "            | NUMBER\n",
        "\n",
        "    cross_above: series \"crosses_above\" series\n",
        "    cross_below: series \"crosses_below\" series\n",
        "\n",
        "    series: CNAME (\"[\" NUMBER \"]\")?\n",
        "\n",
        "    indicator: CNAME \"(\" operand \",\" NUMBER \")\"\n",
        "\n",
        "    OP: \">\" | \"<\" | \">=\" | \"<=\" | \"==\"\n",
        "\n",
        "    %import common.CNAME\n",
        "    %import common.NUMBER\n",
        "    %import common.WS\n",
        "    %ignore WS\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "ok0NYJzKckTx"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dsl_parser = Lark(dsl_grammar, start=\"start\", parser=\"lalr\")\n"
      ],
      "metadata": {
        "id": "z-k0i6SxdcH9"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def SMA(series, period):\n",
        "    \"\"\"Simple Moving Average\"\"\"\n",
        "    return series.rolling(window=period).mean()\n",
        "\n",
        "def RSI(series, period):\n",
        "    \"\"\"Relative Strength Index\"\"\"\n",
        "    delta = series.diff()\n",
        "\n",
        "    gain = delta.where(delta > 0, 0)\n",
        "    loss = -delta.where(delta < 0, 0)\n",
        "\n",
        "    avg_gain = gain.rolling(period).mean()\n",
        "    avg_loss = loss.rolling(period).mean()\n",
        "\n",
        "    rs = avg_gain / avg_loss\n",
        "    rsi = 100 - (100 / (1 + rs))\n",
        "\n",
        "    return rsi\n"
      ],
      "metadata": {
        "id": "hHePWoREe5gx"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entry_rule = \"Buy when the close price is above the 20-day moving average\"\n",
        "exit_rule  = \"Exit when RSI(14) is below 30\"\n",
        "\n",
        "result = run_pipeline(entry_rule, exit_rule, df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mO72fvGWb7GU",
        "outputId": "bcdc7be0-dab7-4b88-d414-fe63dae9b524"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================\n",
            "1. NL → JSON\n",
            "========================\n",
            "{'entry': [{'left': 'close', 'operator': '>', 'right': 'sma(close,20)'}], 'exit': [{'left': 'rsi(close,14)', 'operator': '<', 'right': 30}]}\n",
            "\n",
            "========================\n",
            "2. JSON → DSL\n",
            "========================\n",
            "ENTRY: close > sma(close,20)\n",
            "EXIT: rsi(close,14) < 30\n",
            "\n",
            "========================\n",
            "3. DSL → AST\n",
            "========================\n",
            "{'entry': [{'type': 'comparison', 'left': 'close', 'operator': '>', 'right': {'type': 'indicator', 'name': 'sma', 'series': 'close', 'period': 20}}], 'exit': [{'type': 'comparison', 'left': {'type': 'indicator', 'name': 'rsi', 'series': 'close', 'period': 14}, 'operator': '<', 'right': Token('NUMBER', '30')}]}\n",
            "\n",
            "========================\n",
            "4. AST → Python Code → Signals\n",
            "========================\n",
            "            entry   exit\n",
            "2023-01-01  False  False\n",
            "2023-01-02  False  False\n",
            "2023-01-03  False  False\n",
            "2023-01-04  False  False\n",
            "2023-01-05  False  False\n",
            "\n",
            "========================\n",
            "5. Running Backtest\n",
            "========================\n",
            "\n",
            "Final Results:\n",
            "Total Return (%) = 143.11653691695906\n",
            "Max Drawdown (%) = -3.1271098515427282\n",
            "Number of Trades = 1\n",
            "\n",
            "Trades Log:\n",
            "{'entry_index': '2023-01-20 00:00:00', 'entry_fill_index': Timestamp('2023-01-21 00:00:00'), 'entry_price': 105.37145600049757, 'exit_index': '2023-04-10 00:00:00', 'exit_fill_index': Timestamp('2023-04-10 00:00:00'), 'exit_price': 150.8039787268894, 'shares': 949.0236141325388, 'pnl': 43116.53691695907, 'return_pct': 43.11653691695907}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile nl_parser.py\n",
        "import re\n",
        "\n",
        "# ---------------------------------------------\n",
        "# BASIC HELPERS\n",
        "# ---------------------------------------------\n",
        "def normalize_text(text):\n",
        "    return re.sub(r\"\\s+\", \" \", text.lower()).strip()\n",
        "\n",
        "def extract_numbers(text):\n",
        "    text = text.lower()\n",
        "    nums = re.findall(r\"\\d+\", text)\n",
        "    nums = [int(n) for n in nums] if nums else []\n",
        "\n",
        "    if \"million\" in text and nums:\n",
        "        nums = [nums[0] * 1_000_000]\n",
        "    if \"thousand\" in text and nums:\n",
        "        nums = [nums[0] * 1000]\n",
        "\n",
        "    return nums\n",
        "\n",
        "\n",
        "# ---------------------------------------------\n",
        "# CROSS CONDITION (price crosses above yesterday’s high)\n",
        "# ---------------------------------------------\n",
        "def parse_cross_condition(sentence):\n",
        "    s = normalize_text(sentence)\n",
        "\n",
        "    if \"crosses above\" in s or \"cross above\" in s:\n",
        "        left = \"close\"\n",
        "\n",
        "        if \"yesterday\" in s and \"high\" in s:\n",
        "            right = \"high[1]\"\n",
        "        elif \"yesterday\" in s and \"low\" in s:\n",
        "            right = \"low[1]\"\n",
        "        else:\n",
        "            right = None\n",
        "\n",
        "        if right:\n",
        "            return {\"left\": left, \"operator\": \"crosses_above\", \"right\": right}\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "# ---------------------------------------------\n",
        "# PERCENT INCREASE COMPARED TO LAST WEEK\n",
        "# \"volume increases by more than 30 percent compared to last week\"\n",
        "# ---------------------------------------------\n",
        "def parse_percent_last_week(sentence):\n",
        "    s = normalize_text(sentence)\n",
        "\n",
        "    if \"percent\" in s and (\"increase\" in s or \"increases\" in s):\n",
        "        nums = re.findall(r\"\\d+\", s)\n",
        "        if not nums:\n",
        "            return None\n",
        "\n",
        "        percent = int(nums[0])\n",
        "\n",
        "        if \"volume\" not in s:\n",
        "            return None\n",
        "\n",
        "        if \"last week\" in s:\n",
        "            base = \"volume[7]\"\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "        multiplier = 1 + (percent / 100)\n",
        "        right = f\"{base} * {multiplier}\"\n",
        "\n",
        "        return {\"left\": \"volume\", \"operator\": \">\", \"right\": right}\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "# ---------------------------------------------\n",
        "# MAIN CONDITION HANDLER\n",
        "# ---------------------------------------------\n",
        "def parse_one_condition(sentence):\n",
        "    s = normalize_text(sentence)\n",
        "\n",
        "    # 1) Percent change rule\n",
        "    rule = parse_percent_last_week(sentence)\n",
        "    if rule:\n",
        "        return rule\n",
        "\n",
        "    # 2) Cross condition\n",
        "    rule = parse_cross_condition(sentence)\n",
        "    if rule:\n",
        "        return rule\n",
        "\n",
        "    # 3) RSI rule\n",
        "    if \"rsi\" in s:\n",
        "        nums = re.findall(r\"\\d+\", s)\n",
        "        period = int(nums[0]) if nums else 14\n",
        "        threshold = int(nums[-1]) if len(nums) >= 2 else 30\n",
        "\n",
        "        op = \"<\" if \"below\" in s else \">\" if \"above\" in s else None\n",
        "\n",
        "        return {\"left\": f\"rsi(close,{period})\", \"operator\": op, \"right\": threshold}\n",
        "\n",
        "    # 4) Basic comparisons (close, volume, SMA)\n",
        "    left = None\n",
        "    op = None\n",
        "    right = None\n",
        "\n",
        "    if \"close\" in s or \"price\" in s:\n",
        "        left = \"close\"\n",
        "    elif \"volume\" in s:\n",
        "        left = \"volume\"\n",
        "\n",
        "    if \"above\" in s:\n",
        "        op = \">\"\n",
        "    elif \"below\" in s:\n",
        "        op = \"<\"\n",
        "    elif \"equal\" in s:\n",
        "        op = \"==\"\n",
        "\n",
        "    if \"moving average\" in s or \"ma\" in s:\n",
        "        nums = extract_numbers(s)\n",
        "        period = nums[0] if nums else 20\n",
        "        right = f\"sma({left},{period})\"\n",
        "\n",
        "    if right is None:\n",
        "        nums = extract_numbers(s)\n",
        "        if nums:\n",
        "            right = nums[0]\n",
        "\n",
        "    if left and op and right is not None:\n",
        "        return {\"left\": left, \"operator\": op, \"right\": right}\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "# ---------------------------------------------\n",
        "# ENTRY POINT: NL → JSON RULES\n",
        "# ---------------------------------------------\n",
        "def nl_to_json_rules(text):\n",
        "    t = normalize_text(text)\n",
        "\n",
        "    is_entry = any(x in t for x in [\"buy\", \"enter\", \"trigger entry\"])\n",
        "    is_exit = any(x in t for x in [\"exit\", \"sell\"])\n",
        "\n",
        "    entry_rules = []\n",
        "    exit_rules = []\n",
        "\n",
        "    parts = re.split(r\"\\band\\b\", t)\n",
        "\n",
        "    for part in parts:\n",
        "        rule = parse_one_condition(part)\n",
        "        if rule:\n",
        "            if is_exit:\n",
        "                exit_rules.append(rule)\n",
        "            else:\n",
        "                entry_rules.append(rule)\n",
        "\n",
        "    return {\"entry\": entry_rules, \"exit\": exit_rules}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbCv4rSnfAfy",
        "outputId": "47c237e2-0edc-4c3e-fdcf-6ed7f3be059b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing nl_parser.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile dsl_parser.py\n",
        "from lark import Lark\n",
        "\n",
        "dsl_grammar = r\"\"\"\n",
        "    start: entry exit?\n",
        "\n",
        "    entry: \"ENTRY:\" expr\n",
        "    exit: \"EXIT:\" expr\n",
        "\n",
        "    ?expr: expr \"AND\" expr   -> and_op\n",
        "         | expr \"OR\" expr    -> or_op\n",
        "         | condition\n",
        "         | \"(\" expr \")\"\n",
        "\n",
        "    ?condition: comparison\n",
        "              | cross_above\n",
        "              | cross_below\n",
        "\n",
        "    comparison: operand OP operand\n",
        "\n",
        "    ?operand: indicator\n",
        "            | series\n",
        "            | NUMBER\n",
        "\n",
        "    cross_above: series \"crosses_above\" series\n",
        "    cross_below: series \"crosses_below\" series\n",
        "\n",
        "    series: CNAME (\"[\" NUMBER \"]\")?\n",
        "\n",
        "    indicator: CNAME \"(\" operand \",\" NUMBER \")\"\n",
        "\n",
        "    OP: \">\" | \"<\" | \">=\" | \"<=\" | \"==\"\n",
        "\n",
        "    %import common.CNAME\n",
        "    %import common.NUMBER\n",
        "    %import common.WS\n",
        "    %ignore WS\n",
        "\"\"\"\n",
        "\n",
        "# IMPORTANT: use LALR, not Earley\n",
        "dsl_parser = Lark(dsl_grammar, start=\"start\", parser=\"lalr\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlD-PIkdieJu",
        "outputId": "55a2c452-5fcd-45c8-c78e-9b4ffd29c3ea"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing dsl_parser.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ast_builder.py\n",
        "from lark import Transformer\n",
        "\n",
        "class DSLtoAST(Transformer):\n",
        "\n",
        "    def entry(self, items):\n",
        "        return (\"entry\", items[0])\n",
        "\n",
        "    def exit(self, items):\n",
        "        return (\"exit\", items[0])\n",
        "\n",
        "    def and_op(self, items):\n",
        "        return {\n",
        "            \"type\": \"and\",\n",
        "            \"left\": items[0],\n",
        "            \"right\": items[1]\n",
        "        }\n",
        "\n",
        "    def or_op(self, items):\n",
        "        return {\n",
        "            \"type\": \"or\",\n",
        "            \"left\": items[0],\n",
        "            \"right\": items[1]\n",
        "        }\n",
        "\n",
        "    def comparison(self, items):\n",
        "        return {\n",
        "            \"type\": \"comparison\",\n",
        "            \"left\": items[0],\n",
        "            \"operator\": items[1].value,\n",
        "            \"right\": items[2]\n",
        "        }\n",
        "\n",
        "    def cross_above(self, items):\n",
        "        return {\n",
        "            \"type\": \"cross\",\n",
        "            \"direction\": \"above\",\n",
        "            \"left\": items[0],\n",
        "            \"right\": items[1]\n",
        "        }\n",
        "\n",
        "    def cross_below(self, items):\n",
        "        return {\n",
        "            \"type\": \"cross\",\n",
        "            \"direction\": \"below\",\n",
        "            \"left\": items[0],\n",
        "            \"right\": items[1]\n",
        "        }\n",
        "\n",
        "    def series(self, items):\n",
        "        if len(items) == 2:\n",
        "            return f\"{items[0]}[{items[1]}]\"\n",
        "        return items[0].value\n",
        "\n",
        "    def indicator(self, items):\n",
        "        return {\n",
        "            \"type\": \"indicator\",\n",
        "            \"name\": items[0].value.lower(),\n",
        "            \"series\": items[1],\n",
        "            \"period\": int(items[2])\n",
        "        }\n",
        "\n",
        "\n",
        "def build_final_ast(tree):\n",
        "    \"\"\"\n",
        "    Returns: {\"entry\":[...], \"exit\":[...]}\n",
        "    \"\"\"\n",
        "    final_ast = {\"entry\": [], \"exit\": []}\n",
        "\n",
        "    for section, ast in tree:\n",
        "        if section == \"entry\":\n",
        "            final_ast[\"entry\"].append(ast)\n",
        "        elif section == \"exit\":\n",
        "            final_ast[\"exit\"].append(ast)\n",
        "\n",
        "    return final_ast\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69W-2Gn8ih0a",
        "outputId": "29bc4b4f-7c3f-4cc7-8cfd-9be4e9d267e8"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing ast_builder.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile code_generator.py\n",
        "from lark.lexer import Token\n",
        "\n",
        "# ============================================================\n",
        "# Convert AST Node → Pandas Expression String\n",
        "# ============================================================\n",
        "def generate_python_expr(node):\n",
        "    \"\"\"Convert AST node into a valid pandas-evaluable expression string.\"\"\"\n",
        "\n",
        "    # ---------------------------------------------------\n",
        "    # 1. COMPARISON NODE\n",
        "    # ---------------------------------------------------\n",
        "    if node[\"type\"] == \"comparison\":\n",
        "        left = node[\"left\"]\n",
        "        op = node[\"operator\"]\n",
        "        right = node[\"right\"]\n",
        "\n",
        "        # Token → int\n",
        "        if isinstance(right, Token) and right.type == \"NUMBER\":\n",
        "            right = int(right.value)\n",
        "\n",
        "        # LEFT SIDE\n",
        "        if isinstance(left, dict) and left.get(\"type\") == \"indicator\":\n",
        "            left_expr = generate_python_expr(left)\n",
        "\n",
        "        elif isinstance(left, str):\n",
        "            if \"[\" in left:        # e.g. volume[7]\n",
        "                col, lag = left.split(\"[\")\n",
        "                lag = lag.replace(\"]\", \"\")\n",
        "                left_expr = f\"df['{col}'].shift({lag})\"\n",
        "            else:\n",
        "                left_expr = f\"df['{left}']\"\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported left operand:\", left)\n",
        "\n",
        "        # RIGHT SIDE\n",
        "        if isinstance(right, (int, float)):\n",
        "            right_expr = str(right)\n",
        "\n",
        "        elif isinstance(right, str):\n",
        "            if \"[\" in right:        # e.g. high[1]\n",
        "                col, lag = right.split(\"[\")\n",
        "                lag = lag.replace(\"]\", \"\")\n",
        "                right_expr = f\"df['{col}'].shift({lag})\"\n",
        "            else:\n",
        "                right_expr = f\"df['{right}']\"\n",
        "\n",
        "        elif isinstance(right, dict) and right.get(\"type\") == \"indicator\":\n",
        "            right_expr = generate_python_expr(right)\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported right operand:\", right)\n",
        "\n",
        "        return f\"({left_expr} {op} {right_expr})\"\n",
        "\n",
        "    # ---------------------------------------------------\n",
        "    # 2. INDICATOR NODE (SMA, RSI)\n",
        "    # ---------------------------------------------------\n",
        "    if node[\"type\"] == \"indicator\":\n",
        "        name = node[\"name\"].upper()\n",
        "        series = node[\"series\"]\n",
        "        period = node[\"period\"]\n",
        "\n",
        "        if isinstance(series, dict):   # nested indicator\n",
        "            series_expr = generate_python_expr(series)\n",
        "\n",
        "        elif \"[\" in series:            # e.g. close[5]\n",
        "            col, lag = series.split(\"[\")\n",
        "            lag = lag.replace(\"]\", \"\")\n",
        "            series_expr = f\"df['{col}'].shift({lag})\"\n",
        "\n",
        "        else:\n",
        "            series_expr = f\"df['{series}']\"\n",
        "\n",
        "        return f\"{name}({series_expr}, {period})\"\n",
        "\n",
        "    # ---------------------------------------------------\n",
        "    # 3. CROSS EVENTS (crosses_above / crosses_below)\n",
        "    # ---------------------------------------------------\n",
        "    if node[\"type\"] == \"cross\":\n",
        "        left = node[\"left\"]\n",
        "        right = node[\"right\"]\n",
        "\n",
        "        # Left side\n",
        "        if isinstance(left, dict):\n",
        "            left_now = generate_python_expr(left)\n",
        "            left_prev = f\"({left_now}).shift(1)\"\n",
        "        else:\n",
        "            left_now = f\"df['{left}']\"\n",
        "            left_prev = f\"df['{left}'].shift(1)\"\n",
        "\n",
        "        # Right side\n",
        "        if \"[\" in right:           # high[1]\n",
        "            col, lag = right.split(\"[\")\n",
        "            lag = int(lag.replace(\"]\", \"\"))\n",
        "            right_now = f\"df['{col}'].shift({lag})\"\n",
        "            right_prev = f\"df['{col}'].shift({lag+1})\"\n",
        "\n",
        "        else:\n",
        "            right_now = f\"df['{right}']\"\n",
        "            right_prev = f\"df['{right}'].shift(1)\"\n",
        "\n",
        "        # CROSS ABOVE\n",
        "        if node[\"direction\"] == \"above\":\n",
        "            return (\n",
        "                f\"((({left_prev}) <= ({right_prev})) \"\n",
        "                f\"& (({left_now}) > ({right_now})))\"\n",
        "            )\n",
        "\n",
        "        # CROSS BELOW\n",
        "        if node[\"direction\"] == \"below\":\n",
        "            return (\n",
        "                f\"((({left_prev}) >= ({right_prev})) \"\n",
        "                f\"& (({left_now}) < ({right_now})))\"\n",
        "            )\n",
        "\n",
        "    # ---------------------------------------------------\n",
        "    # 4. LOGICAL OPERATORS\n",
        "    # ---------------------------------------------------\n",
        "    if node[\"type\"] == \"and\":\n",
        "        return f\"({generate_python_expr(node['left'])} & {generate_python_expr(node['right'])})\"\n",
        "\n",
        "    if node[\"type\"] == \"or\":\n",
        "        return f\"({generate_python_expr(node['left'])} | {generate_python_expr(node['right'])})\"\n",
        "\n",
        "    # ---------------------------------------------------\n",
        "    # UNKNOWN NODE\n",
        "    # ---------------------------------------------------\n",
        "    raise ValueError(\"Unknown AST node:\", node)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Convert Full AST → Python Function Code\n",
        "# ============================================================\n",
        "def ast_to_python_code(final_ast):\n",
        "    entry_expr = \"\"\n",
        "    exit_expr = \"\"\n",
        "\n",
        "    if final_ast[\"entry\"]:\n",
        "        entry_expr = generate_python_expr(final_ast[\"entry\"][0])\n",
        "    if final_ast[\"exit\"]:\n",
        "        exit_expr = generate_python_expr(final_ast[\"exit\"][0])\n",
        "\n",
        "    code = f\"\"\"\n",
        "def run_strategy(df):\n",
        "    import pandas as pd\n",
        "\n",
        "    signals = pd.DataFrame(index=df.index)\n",
        "    signals['entry'] = {entry_expr}\n",
        "    signals['exit'] = {exit_expr}\n",
        "\n",
        "    return signals\n",
        "\"\"\"\n",
        "    return code\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7UA8DXnilTY",
        "outputId": "94b4a301-676d-43fb-f1c0-17e332b47ee5"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing code_generator.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile indicators.py\n",
        "import pandas as pd\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Simple Moving Average\n",
        "# -----------------------------------------------------------\n",
        "def SMA(series, period):\n",
        "    \"\"\"\n",
        "    Calculate Simple Moving Average.\n",
        "    series : pandas.Series (df['close'])\n",
        "    period : int\n",
        "    \"\"\"\n",
        "    return series.rolling(window=period).mean()\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Relative Strength Index (RSI)\n",
        "# -----------------------------------------------------------\n",
        "def RSI(series, period=14):\n",
        "    \"\"\"\n",
        "    Compute RSI using Wilder's smoothing.\n",
        "    \"\"\"\n",
        "    delta = series.diff()\n",
        "\n",
        "    gain = delta.where(delta > 0, 0.0)\n",
        "    loss = -delta.where(delta < 0, 0.0)\n",
        "\n",
        "    avg_gain = gain.rolling(period).mean()\n",
        "    avg_loss = loss.rolling(period).mean()\n",
        "\n",
        "    rs = avg_gain / avg_loss\n",
        "\n",
        "    rsi = 100 - (100 / (1 + rs))\n",
        "    return rsi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6NPBrF9imwV",
        "outputId": "0aacebe8-6edc-4b81-b296-b98f1390cb1e"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing indicators.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile backtest.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def backtest_signals(df, signals, initial_capital=100000.0, slippage=0.0, commission=0.0):\n",
        "    \"\"\"\n",
        "    Simple backtesting engine that trades based on ENTRY and EXIT signals.\n",
        "\n",
        "    Args:\n",
        "        df (DataFrame): OHLCV data with columns ['open','high','low','close','volume']\n",
        "        signals (DataFrame): Boolean DataFrame with columns ['entry','exit']\n",
        "        initial_capital (float): Starting cash\n",
        "        slippage (float): Per-share slippage\n",
        "        commission (float): Fixed commission per trade\n",
        "\n",
        "    Returns:\n",
        "        dict with:\n",
        "        - trades (list)\n",
        "        - equity (Series)\n",
        "        - final_capital\n",
        "        - total_return_pct\n",
        "        - max_drawdown_pct\n",
        "        - num_trades\n",
        "    \"\"\"\n",
        "\n",
        "    assert 'entry' in signals.columns, \"signals must include 'entry'\"\n",
        "    assert 'exit' in signals.columns, \"signals must include 'exit'\"\n",
        "    assert len(df) == len(signals), \"df and signals must have same length\"\n",
        "\n",
        "    signals = signals.reindex(df.index)\n",
        "\n",
        "    cash = float(initial_capital)\n",
        "    position = 0.0  # number of shares (fractional allowed)\n",
        "    entry_price = None\n",
        "\n",
        "    trades = []\n",
        "    equity_values = []\n",
        "    equity_index = []\n",
        "\n",
        "    idxs = list(df.index)\n",
        "    n = len(idxs)\n",
        "\n",
        "    for i, idx in enumerate(idxs):\n",
        "        row = df.loc[idx]\n",
        "        close_price = float(row[\"close\"])\n",
        "\n",
        "        # =============================================================\n",
        "        # ENTRY\n",
        "        # =============================================================\n",
        "        if position == 0 and signals.loc[idx, \"entry\"]:\n",
        "            if i + 1 < n:\n",
        "                fill_idx = idxs[i+1]\n",
        "                fill_price = float(df.loc[fill_idx][\"open\"])\n",
        "            else:\n",
        "                fill_idx = idx\n",
        "                fill_price = close_price\n",
        "\n",
        "            buy_price = fill_price + slippage\n",
        "            shares = cash / buy_price if buy_price > 0 else 0\n",
        "\n",
        "            if shares > 0:\n",
        "                position = shares\n",
        "                entry_price = buy_price\n",
        "                cash -= commission  # commission on entry\n",
        "\n",
        "                trades.append({\n",
        "                    \"entry_index\": str(idx),\n",
        "                    \"entry_fill_index\": str(fill_idx),\n",
        "                    \"entry_price\": float(buy_price),\n",
        "                    \"exit_index\": None,\n",
        "                    \"exit_fill_index\": None,\n",
        "                    \"exit_price\": None,\n",
        "                    \"shares\": float(shares),\n",
        "                    \"pnl\": None,\n",
        "                    \"return_pct\": None\n",
        "                })\n",
        "\n",
        "        # =============================================================\n",
        "        # EXIT\n",
        "        # =============================================================\n",
        "        elif position > 0 and signals.loc[idx, \"exit\"]:\n",
        "            if i + 1 < n:\n",
        "                fill_idx = idxs[i+1]\n",
        "                fill_price = float(df.loc[fill_idx][\"open\"])\n",
        "            else:\n",
        "                fill_idx = idx\n",
        "                fill_price = close_price\n",
        "\n",
        "            sell_price = fill_price - slippage\n",
        "\n",
        "            proceeds = position * sell_price\n",
        "            cost = position * entry_price\n",
        "\n",
        "            pnl = proceeds - cost - commission\n",
        "            return_pct = pnl / cost if cost != 0 else 0\n",
        "\n",
        "            last_trade = trades[-1]\n",
        "            last_trade[\"exit_index\"] = str(idx)\n",
        "            last_trade[\"exit_fill_index\"] = str(fill_idx)\n",
        "            last_trade[\"exit_price\"] = float(sell_price)\n",
        "            last_trade[\"pnl\"] = float(pnl)\n",
        "            last_trade[\"return_pct\"] = float(return_pct) * 100.0\n",
        "\n",
        "            cash += proceeds\n",
        "            position = 0\n",
        "            entry_price = None\n",
        "\n",
        "        # =============================================================\n",
        "        # DAILY MARK TO MARKET\n",
        "        # =============================================================\n",
        "        mtm_equity = cash + position * close_price\n",
        "        equity_values.append(mtm_equity)\n",
        "        equity_index.append(idx)\n",
        "\n",
        "    # =============================================================\n",
        "    # FORCE CLOSE at last price if still in position\n",
        "    # =============================================================\n",
        "    if position > 0:\n",
        "        last_idx = idxs[-1]\n",
        "        last_close = float(df.loc[last_idx, \"close\"])\n",
        "\n",
        "        sell_price = last_close - slippage\n",
        "        proceeds = position * sell_price\n",
        "        cost = trades[-1][\"shares\"] * trades[-1][\"entry_price\"]\n",
        "\n",
        "        pnl = proceeds - cost - commission\n",
        "        return_pct = pnl / cost if cost != 0 else 0\n",
        "\n",
        "        last_trade = trades[-1]\n",
        "        last_trade[\"exit_index\"] = str(last_idx)\n",
        "        last_trade[\"exit_fill_index\"] = str(last_idx)\n",
        "        last_trade[\"exit_price\"] = float(sell_price)\n",
        "        last_trade[\"pnl\"] = float(pnl)\n",
        "        last_trade[\"return_pct\"] = float(return_pct) * 100.0\n",
        "\n",
        "        cash += proceeds\n",
        "        position = 0\n",
        "\n",
        "        equity_values[-1] = cash\n",
        "\n",
        "    # =============================================================\n",
        "    # EQUITY CURVE & METRICS\n",
        "    # =============================================================\n",
        "    equity = pd.Series(equity_values, index=equity_index)\n",
        "\n",
        "    final_capital = float(equity.iloc[-1])\n",
        "    total_return_pct = ((final_capital - initial_capital) / initial_capital) * 100.0\n",
        "\n",
        "    roll_max = equity.cummax()\n",
        "    drawdown = (equity - roll_max) / roll_max\n",
        "    max_drawdown_pct = float(drawdown.min() * 100.0)\n",
        "\n",
        "    results = {\n",
        "        \"trades\": trades,\n",
        "        \"equity\": equity,\n",
        "        \"final_capital\": final_capital,\n",
        "        \"total_return_pct\": total_return_pct,\n",
        "        \"max_drawdown_pct\": max_drawdown_pct,\n",
        "        \"num_trades\": len(trades)\n",
        "    }\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ES5VucFqiovo",
        "outputId": "7c81674d-11b8-436b-be74-816e1ad1162d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing backtest.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile demo.py\n",
        "import pandas as pd\n",
        "\n",
        "# -----------------------------------------\n",
        "# IMPORTING MODULES FROM PROJECT FILES\n",
        "# -----------------------------------------\n",
        "from nl_parser import nl_to_json_rules\n",
        "from dsl_parser import dsl_parser\n",
        "from ast_builder import DSLtoAST, build_final_ast\n",
        "from code_generator import generate_python_expr\n",
        "from indicators import SMA, RSI\n",
        "from backtest import backtest_signals\n",
        "\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# JSON → DSL (Simple converter)\n",
        "# ---------------------------------------------------\n",
        "def json_to_dsl(json_rules):\n",
        "    entry_rules = []\n",
        "    exit_rules = []\n",
        "\n",
        "    for rule in json_rules[\"entry\"]:\n",
        "        entry_rules.append(f\"{rule['left']} {rule['operator']} {rule['right']}\")\n",
        "\n",
        "    for rule in json_rules[\"exit\"]:\n",
        "        exit_rules.append(f\"{rule['left']} {rule['operator']} {rule['right']}\")\n",
        "\n",
        "    dsl = \"\"\n",
        "    if entry_rules:\n",
        "        dsl += \"ENTRY: \" + \" AND \".join(entry_rules) + \"\\n\"\n",
        "    if exit_rules:\n",
        "        dsl += \"EXIT: \" + \" AND \".join(exit_rules)\n",
        "\n",
        "    return dsl.strip()\n",
        "\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# DSL → AST\n",
        "# ---------------------------------------------------\n",
        "def parse_dsl_to_ast(dsl_text):\n",
        "    tree = dsl_parser.parse(dsl_text)\n",
        "    transformer = DSLtoAST()\n",
        "    parsed = transformer.transform(tree)\n",
        "\n",
        "    final_ast = {\"entry\": [], \"exit\": []}\n",
        "\n",
        "    for node in parsed:\n",
        "        section, ast = node\n",
        "        final_ast[section].append(ast)\n",
        "\n",
        "    return final_ast\n",
        "\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# AST → Signals (eval python expressions)\n",
        "# ---------------------------------------------------\n",
        "def ast_to_signals(df, ast):\n",
        "    signals = pd.DataFrame(index=df.index)\n",
        "    signals[\"entry\"] = False\n",
        "    signals[\"exit\"] = False\n",
        "\n",
        "    if ast[\"entry\"]:\n",
        "        expr = generate_python_expr(ast[\"entry\"][0])\n",
        "        signals[\"entry\"] = eval(expr)\n",
        "\n",
        "    if ast[\"exit\"]:\n",
        "        expr = generate_python_expr(ast[\"exit\"][0])\n",
        "        signals[\"exit\"] = eval(expr)\n",
        "\n",
        "    return signals.fillna(False)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# END-TO-END PIPELINE\n",
        "# ---------------------------------------------------\n",
        "def run_pipeline(entry_nl, exit_nl, df):\n",
        "    print(\"\\n========================\")\n",
        "    print(\"1. NL → JSON\")\n",
        "    print(\"========================\")\n",
        "    entry_json = nl_to_json_rules(entry_nl)\n",
        "    exit_json = nl_to_json_rules(exit_nl)\n",
        "\n",
        "    combined_json = {\n",
        "        \"entry\": entry_json[\"entry\"],\n",
        "        \"exit\": exit_json[\"exit\"]\n",
        "    }\n",
        "    print(combined_json)\n",
        "\n",
        "    print(\"\\n========================\")\n",
        "    print(\"2. JSON → DSL\")\n",
        "    print(\"========================\")\n",
        "    dsl = json_to_dsl(combined_json)\n",
        "    print(dsl)\n",
        "\n",
        "    print(\"\\n========================\")\n",
        "    print(\"3. DSL → AST\")\n",
        "    print(\"========================\")\n",
        "    ast = parse_dsl_to_ast(dsl)\n",
        "    print(ast)\n",
        "\n",
        "    print(\"\\n========================\")\n",
        "    print(\"4. AST → Signals\")\n",
        "    print(\"========================\")\n",
        "    signals = ast_to_signals(df, ast)\n",
        "    print(signals.head())\n",
        "\n",
        "    print(\"\\n========================\")\n",
        "    print(\"5. Backtest\")\n",
        "    print(\"========================\")\n",
        "    result = backtest_signals(df, signals)\n",
        "\n",
        "    print(\"\\nFinal Backtest Result\")\n",
        "    print(\"Total Return (%) =\", result[\"total_return_pct\"])\n",
        "    print(\"Max Drawdown (%) =\", result[\"max_drawdown_pct\"])\n",
        "    print(\"Number of Trades =\", result[\"num_trades\"])\n",
        "\n",
        "    print(\"\\nTrades Log:\")\n",
        "    for t in result[\"trades\"]:\n",
        "        print(t)\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# SAMPLE HOW TO RUN (Uncomment to test)\n",
        "# ---------------------------------------------------\n",
        "\"\"\"\n",
        "df = pd.read_csv(\"ohlcv_sample.csv\")\n",
        "\n",
        "entry_rule = \"Buy when the close price is above the 20-day moving average\"\n",
        "exit_rule  = \"Exit when RSI(14) is below 30\"\n",
        "\n",
        "run_pipeline(entry_rule, exit_rule, df)\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_co7Avhiqa4",
        "outputId": "9f3b7d78-85ae-407a-d0a8-02b910fc002a"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing demo.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r project.zip /\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-2tYHYfyZog",
        "outputId": "c17eb104-44d7-488e-f733-48b2e720a200"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tzip warning: name not matched: /content/my_project_folder\n",
            "\n",
            "zip error: Nothing to do! (try: zip -r project.zip . -i /content/my_project_folder)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "chQsaZ4DpI6k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}